{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021 March Madness Bracket Predictor\n",
    "\n",
    "### Predicts and generates a 2021 March Madness bracket.\n",
    "\n",
    "Developers:\n",
    "- Brady Lange (03/12/2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configure settings\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "# pd.set_option(\"display.max.rows\", None)\n",
    "# pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.abspath(\"..\")\n",
    "data_path = os.path.join(base_path, \"data\")\n",
    "\n",
    "data_file_paths = {}\n",
    "exclude_dirs = [\"2020_challenge_data\"]\n",
    "\n",
    "for root, dirs, files in os.walk(data_path, topdown=True):\n",
    "    # Exclude last year's challenge data and output files\n",
    "    dirs[:] = [d for d in dirs if d not in exclude_dirs]\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            data_file_paths[file_name[:-4]] = os.path.join(root, file_name)\n",
    "\n",
    "# Basic data\n",
    "m_ncaa_tourney_compact_results_df = pd.read_csv(data_file_paths[\"m_ncaa_tourney_compact_results\"])\n",
    "m_ncaa_tourney_seeds_df = pd.read_csv(data_file_paths[\"m_ncaa_tourney_seeds\"])\n",
    "m_regular_season_compact_results_df = pd.read_csv(data_file_paths[\"m_regular_season_compact_results\"])\n",
    "m_seasons_df = pd.read_csv(data_file_paths[\"m_seasons\"])\n",
    "m_teams_df = pd.read_csv(data_file_paths[\"m_teams\"])\n",
    "\n",
    "# Team box scores data\n",
    "m_ncaa_tourney_detailed_results_df = pd.read_csv(data_file_paths[\"m_ncaa_tourney_detailed_results\"])\n",
    "m_regular_season_detailed_results_df = pd.read_csv(data_file_paths[\"m_regular_season_detailed_results\"])\n",
    "\n",
    "# Geography data\n",
    "cities_df = pd.read_csv(data_file_paths[\"cities\"])\n",
    "m_game_cities_df = pd.read_csv(data_file_paths[\"m_game_cities\"])\n",
    "\n",
    "# Public rankings data\n",
    "m_massey_ordinals_df = pd.read_csv(data_file_paths[\"m_massey_ordinals\"])\n",
    "\n",
    "# Supplemental data\n",
    "conferences_df = pd.read_csv(data_file_paths[\"conferences\"])\n",
    "m_conference_tourney_games_df = pd.read_csv(data_file_paths[\"m_conference_tourney_games\"])\n",
    "m_ncaa_tourney_seed_round_slots_df = pd.read_csv(data_file_paths[\"m_ncaa_tourney_seed_round_slots\"])\n",
    "m_ncaa_tourney_slots_df = pd.read_csv(data_file_paths[\"m_ncaa_tourney_slots\"])\n",
    "m_secondary_tourney_compact_results_df = pd.read_csv(data_file_paths[\"m_secondary_tourney_compact_results\"])\n",
    "m_secondary_tourney_teams_df = pd.read_csv(data_file_paths[\"m_secondary_tourney_teams\"])\n",
    "m_team_coaches_df = pd.read_csv(data_file_paths[\"m_team_coaches\"])\n",
    "m_team_conferences_df = pd.read_csv(data_file_paths[\"m_team_conferences\"])\n",
    "# Windows codepage 1252 encoded file\n",
    "m_team_spellings_df = pd.read_csv(data_file_paths[\"m_team_spellings\"], encoding=\"cp1252\")\n",
    "\n",
    "# Sample submission data\n",
    "hist_sample_subm_df = pd.read_csv(data_file_paths[\"m_sample_submission_stage_01\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_df(df, title=\"Data Frame\"):\n",
    "    \"\"\"\n",
    "    Explores a specified Pandas data frame by printing out all of it's metrics\n",
    "    and information neatly.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): Pandas Data Frame to explore.\n",
    "        title (str): Title/name of data frame. Default is 'Data Frame'.\n",
    "        \n",
    "    Returns:\n",
    "        None: Nothing.\n",
    "    \"\"\"\n",
    "    print(\"======================================================================\")\n",
    "    print(\"{0}:\".format(title))\n",
    "    print(\"======================================================================\")\n",
    "    print(\"Data Type:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(type(df), \"\\n\")\n",
    "    print(\"First 5 Rows:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.head(), \"\\n\")\n",
    "    print(\"Last 5 Rows:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.tail(), \"\\n\")\n",
    "    print(\"Description:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.describe(include=np.object), \"\\n\")\n",
    "    print(\"Information:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    df.info()\n",
    "    print(\"\\nNumber of Rows & Columns (Rows, Columns):\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.shape, \"\\n\")\n",
    "    print(\"Number of Rows:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(len(df), \"\\n\")\n",
    "    print(\"Number of Elements (Rows x Columns):\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.size, \"\\n\")\n",
    "    print(\"Columns:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.columns, \"\\n\")\n",
    "    for column in df.columns:\n",
    "        print(\"Column:\")\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        print(column, \"\\n\")\n",
    "        print(\"'{0}' Value Counts:\".format(column))\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        print(df[column].value_counts(), \"\\n\")\n",
    "        print(\"Minimum '{0}' Value:\".format(column))\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        print(df[column].min(), \"\\n\")\n",
    "        print(\"Maximum '{0}' Value:\".format(column))\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        print(df[column].max(), \"\\n\")\n",
    "    print(\"Null Values:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.isnull().sum(), \"\\n\")\n",
    "\n",
    "# Basic data\n",
    "explore_df(df=m_ncaa_tourney_compact_results_df, title=\"Men's NCAA Tourney Compact Results\")\n",
    "explore_df(df=m_ncaa_tourney_seeds_df, title=\"Men's NCAA Tourney Seeds\")\n",
    "explore_df(df=m_regular_season_compact_results_df, title=\"Men's Regular Season Compact Results\")\n",
    "explore_df(df=m_seasons_df, title=\"Men's Seasons\")\n",
    "explore_df(df=m_teams_df, title=\"Men's Teams\")\n",
    "\n",
    "# Team box scores data\n",
    "explore_df(df=m_ncaa_tourney_detailed_results_df, title=\"Men's NCAA Tourney Detailed Results\")\n",
    "explore_df(df=m_regular_season_detailed_results_df, title=\"Men's Regular Season Detailed Results\")\n",
    "\n",
    "# Geography data\n",
    "explore_df(df=cities_df, title=\"Cities\")\n",
    "explore_df(df=m_game_cities_df, title=\"Men's Game Cities\")\n",
    "\n",
    "# Public rankings data\n",
    "explore_df(df=m_massey_ordinals_df, title=\"Men's Massey Ordinals\")\n",
    "\n",
    "# Supplemental data\n",
    "explore_df(df=conferences_df, title=\"Conferences\")\n",
    "explore_df(df=m_conference_tourney_games_df, title=\"Men's Conference Tourney Games\")\n",
    "explore_df(df=m_ncaa_tourney_seed_round_slots_df, title=\"Men's NCAA Tourney Seed Round Slots\")\n",
    "explore_df(df=m_ncaa_tourney_slots_df, title=\"Men's NCAA Tourney Slots\")\n",
    "explore_df(df=m_secondary_tourney_compact_results_df, title=\"Men's Secondary Tourney Compact Results\")\n",
    "explore_df(df=m_secondary_tourney_teams_df, title=\"Men's Secondary Tourney Teams\")\n",
    "explore_df(df=m_team_coaches_df, title=\"Men's Team Coaches\")\n",
    "explore_df(df=m_team_conferences_df, title=\"Men's Team Conferences\")\n",
    "explore_df(df=m_team_spellings_df, title=\"Men's Team Spellings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Users\\brady\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-ee6d73545f07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"NumOT\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"NumOT\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"GameDuration\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\brady\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\brady\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "# # Basic data\n",
    "# print(m_ncaa_tourney_compact_results_df.columns)\n",
    "# print(m_ncaa_tourney_seeds_df.columns)\n",
    "# print(m_regular_season_compact_results_df.columns)\n",
    "# print(m_seasons_df.columns)\n",
    "# print(m_teams_df.columns)\n",
    "\n",
    "# print(len(m_ncaa_tourney_compact_results_df))\n",
    "# print(len(m_ncaa_tourney_seeds_df))\n",
    "# print(len(m_regular_season_compact_results_df))\n",
    "# print(len(m_seasons_df))\n",
    "# print(len(m_teams_df))\n",
    "\n",
    "all_game_compact_results_df = pd.concat([m_ncaa_tourney_compact_results_df, m_regular_season_compact_results_df])\n",
    "all_game_detailed_results_df = pd.concat([m_ncaa_tourney_detailed_results_df, m_regular_season_detailed_results_df])\n",
    "\n",
    "df = m_ncaa_tourney_compact_results_df.merge(\n",
    "    m_teams_df[[\"TeamID\", \"TeamName\"]], left_on=\"WTeamID\", right_on=\"TeamID\", validate=\"many_to_one\"\n",
    ").drop(\n",
    "    \"TeamID\", axis=1\n",
    ").rename(\n",
    "    columns={\"TeamName\": \"WTeamName\"}\n",
    ").merge(\n",
    "    m_teams_df[[\"TeamID\", \"TeamName\"]], left_on=\"LTeamID\", right_on=\"TeamID\"\n",
    ").drop(\n",
    "    \"TeamID\", axis=1\n",
    ").rename(\n",
    "    columns={\"TeamName\": \"LTeamName\"}\n",
    ")\n",
    "df\n",
    "\n",
    "df = all_game_detailed_results_df.merge(\n",
    "    m_teams_df[[\"TeamID\", \"TeamName\"]], left_on=\"WTeamID\", right_on=\"TeamID\", validate=\"many_to_one\"\n",
    ").drop(\n",
    "    \"TeamID\", axis=1\n",
    ").rename(\n",
    "    columns={\"TeamName\": \"WTeamName\"}\n",
    ").merge(\n",
    "    m_teams_df[[\"TeamID\", \"TeamName\"]], left_on=\"LTeamID\", right_on=\"TeamID\"\n",
    ").drop(\n",
    "    \"TeamID\", axis=1\n",
    ").rename(\n",
    "    columns={\"TeamName\": \"LTeamName\"}\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TeamID  Season        PPG     WPerc  Games\n",
      "0        1102    1985  63.083333  0.208333     24\n",
      "1        1103    1985  61.043478  0.391304     23\n",
      "2        1104    1985  68.318519  0.700000     30\n",
      "3        1106    1985  71.625000  0.416667     24\n",
      "4        1108    1985  83.000000  0.760000     25\n",
      "...       ...     ...        ...       ...    ...\n",
      "11589    1366    2005  57.964286  0.000000     28\n",
      "11590    1312    2008  55.931034  0.000000     29\n",
      "11591    1212    2013  49.678571  0.000000     28\n",
      "11592    1212    2015  51.111111  0.000000     27\n",
      "11593    1363    2015  52.265873  0.000000     28\n",
      "\n",
      "[11594 rows x 5 columns]\n",
      "      Season  TeamID      OffEff      DefEff\n",
      "0       2003    1102   74.428571  115.821429\n",
      "1       2003    1103  100.188477  135.788477\n",
      "2       2003    1104   94.599206  147.968254\n",
      "3       2003    1105   97.922222  153.617094\n",
      "4       2003    1106   87.134921  148.186508\n",
      "...      ...     ...         ...         ...\n",
      "6182    2020    1463   94.643651  151.820996\n",
      "6183    2020    1464   95.620072  144.910394\n",
      "6184    2020    1465   98.539095  151.111111\n",
      "6185    2020    1466   87.261905  148.019841\n",
      "6186    2020    1467   80.291111  138.500000\n",
      "\n",
      "[6187 rows x 4 columns]\n",
      "      Season  TeamID  MeanOrdinalRank  MedianOrdinalRank  MasseyOrdinalRank\n",
      "0       2003    1102       156.031250              156.0              172.0\n",
      "1       2003    1103       168.000000              170.5              163.0\n",
      "2       2003    1104        38.031250               37.0               41.0\n",
      "3       2003    1105       308.968750              310.0              310.0\n",
      "4       2003    1106       262.687500              265.5              270.0\n",
      "...      ...     ...              ...                ...                ...\n",
      "5828    2019    1462        67.281250               65.5               57.0\n",
      "5829    2019    1463        77.203125               76.5               73.0\n",
      "5830    2019    1464       273.312500              275.0              258.0\n",
      "5831    2019    1465       205.238095              205.0              203.0\n",
      "5832    2019    1466       303.111111              303.0              304.0\n",
      "\n",
      "[5833 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "GAME_MINS = 40\n",
    "OT_MINS = 5\n",
    "\n",
    "def get_ppg(season_results_df):    \n",
    "    season_results_df = season_results_df.copy()\n",
    "    \n",
    "    season_results_df[\"GameDuration\"] = GAME_MINS + OT_MINS * season_results_df[\"NumOT\"]\n",
    "    \n",
    "    season_results_df[\"WTeamPPG\"] = (season_results_df[\"WScore\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LTeamPPG\"] = (season_results_df[\"LScore\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    w_team_ppg = season_results_df[[\"Season\", \"WTeamID\", \"WTeamPPG\"]]\n",
    "    w_team_ppg = w_team_ppg.groupby([\"Season\", \"WTeamID\"]).agg([(\"WPPG\", \"mean\"), (\"WGames\", \"count\")])\n",
    "    w_team_ppg.columns = w_team_ppg.columns.droplevel(0)\n",
    "    w_team_ppg = w_team_ppg.reset_index()\n",
    "    \n",
    "    l_team_ppg = season_results_df[[\"Season\", \"LTeamID\", \"LTeamPPG\"]]\n",
    "    l_team_ppg = l_team_ppg.groupby([\"Season\", \"LTeamID\"]).agg([(\"LPPG\", \"mean\"), (\"LGames\", \"count\")])\n",
    "    l_team_ppg.columns = l_team_ppg.columns.droplevel(0)\n",
    "    l_team_ppg = l_team_ppg.reset_index()\n",
    "    \n",
    "    ppg_df = pd.merge(w_team_ppg, l_team_ppg, left_on=[\"Season\", \"WTeamID\"], right_on=[\"Season\", \"LTeamID\"], how=\"outer\")\n",
    "    \n",
    "    ppg_df = ppg_df.fillna({\"WTeamID\": ppg_df[\"LTeamID\"], \"WPPG\": 0, \"WGames\": 0, \"LTeamID\": ppg_df[\"WTeamID\"], \"LPPG\": 0, \"LGames\": 0})\n",
    "    \n",
    "    ppg_df[\"PPG\"] = (ppg_df[\"WPPG\"] * ppg_df[\"WGames\"] + ppg_df[\"LPPG\"] * ppg_df[\"LGames\"]) / (ppg_df[\"WGames\"] + ppg_df[\"LGames\"])\n",
    "    ppg_df[\"WPerc\"] = ppg_df[\"WGames\"] / (ppg_df[\"WGames\"] + ppg_df[\"LGames\"])\n",
    "    ppg_df[\"Games\"] = (ppg_df[\"WGames\"] + ppg_df[\"LGames\"]).astype(int)\n",
    "    \n",
    "    ppg_df[\"TeamID\"] = ppg_df[\"WTeamID\"].astype(int)\n",
    "    \n",
    "    ppg_df.drop([\"WTeamID\", \"WPPG\", \"WGames\", \"LTeamID\", \"LPPG\", \"LGames\"], axis=1, inplace=True)\n",
    "    \n",
    "    ppg_df = ppg_df[[\"TeamID\", \"Season\", \"PPG\", \"WPerc\", \"Games\"]]\n",
    "    \n",
    "    return ppg_df\n",
    "    \n",
    "print(get_ppg(m_regular_season_compact_results_df))\n",
    "\n",
    "def get_efficiency(season_results_df):\n",
    "    season_results_df = season_results_df.copy()\n",
    "    \n",
    "    season_results_df[\"GameDuration\"] = GAME_MINS + OT_MINS * season_results_df[\"NumOT\"]\n",
    "    \n",
    "    # Winning teams\n",
    "    # Winning offense\n",
    "    season_results_df[\"WFGM\"] = (season_results_df[\"WFGM\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WFGA\"] = (season_results_df[\"WFGA\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WFGM3\"] = (season_results_df[\"WFGM3\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WFGA3\"] = (season_results_df[\"WFGA3\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WFTM\"] = (season_results_df[\"WFTM\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WFTA\"] = (season_results_df[\"WFTA\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WOR\"] = (season_results_df[\"WOR\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WAst\"] = (season_results_df[\"WAst\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WTO\"] = (season_results_df[\"WTO\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    # Winning defense\n",
    "    season_results_df[\"WDR\"] = (season_results_df[\"WDR\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WStl\"] = (season_results_df[\"WStl\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WBlk\"] = (season_results_df[\"WBlk\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    # Winning offense & defense\n",
    "    season_results_df[\"WPF\"] = (season_results_df[\"WPF\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    # Losing teams\n",
    "    # Losing offense\n",
    "    season_results_df[\"LFGM\"] = (season_results_df[\"LFGM\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LFGA\"] = (season_results_df[\"LFGA\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LFGM3\"] = (season_results_df[\"LFGM3\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LFGA3\"] = (season_results_df[\"LFGA3\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LFTM\"] = (season_results_df[\"LFTM\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LFTA\"] = (season_results_df[\"LFTA\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LOR\"] = (season_results_df[\"LOR\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LAst\"] = (season_results_df[\"LAst\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LTO\"] = (season_results_df[\"LTO\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    # Losing defense\n",
    "    season_results_df[\"LDR\"] = (season_results_df[\"LDR\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LStl\"] = (season_results_df[\"LStl\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LBlk\"] = (season_results_df[\"LBlk\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    # Losing offense & defense\n",
    "    season_results_df[\"LPF\"] = (season_results_df[\"LPF\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    season_results_df[\"WPointsMade\"] = (2 * (season_results_df[\"WFGM\"] - season_results_df[\"WFGM3\"])) + (3 * season_results_df[\"WFGM3\"]) + (1 * season_results_df[\"WFTM\"])\n",
    "    season_results_df[\"WPointsMissed\"] = ((2 * (season_results_df[\"WFGA\"] - season_results_df[\"WFGA3\"])) + (3 * season_results_df[\"WFGA3\"]) + (1 * season_results_df[\"WFTA\"])) - season_results_df[\"WPointsMade\"]\n",
    "    \n",
    "    season_results_df[\"LPointsMade\"] = (2 * (season_results_df[\"LFGM\"] - season_results_df[\"LFGM3\"])) + (3 * season_results_df[\"LFGM3\"]) + (1 * season_results_df[\"LFTM\"])\n",
    "    season_results_df[\"LPointsMissed\"] = ((2 * (season_results_df[\"LFGA\"] - season_results_df[\"LFGA3\"])) + (3 * season_results_df[\"LFGA3\"]) + (1 * season_results_df[\"LFTA\"])) - season_results_df[\"LPointsMade\"]\n",
    "    \n",
    "    season_results_df[\"WOffEff\"] = season_results_df[\"WPointsMade\"] + season_results_df[\"WAst\"] + season_results_df[\"WOR\"]\n",
    "    season_results_df[\"WDefEff\"] = season_results_df[\"LPointsMissed\"] + season_results_df[\"LTO\"] + season_results_df[\"WDR\"] + season_results_df[\"WStl\"] + season_results_df[\"WBlk\"] + season_results_df[\"WPF\"]\n",
    "    \n",
    "    season_results_df[\"LOffEff\"] = season_results_df[\"LPointsMade\"] + season_results_df[\"LAst\"] + season_results_df[\"LOR\"]\n",
    "    season_results_df[\"LDefEff\"] = season_results_df[\"WPointsMissed\"] + season_results_df[\"WTO\"] + season_results_df[\"LDR\"] + season_results_df[\"LStl\"] + season_results_df[\"LBlk\"] + season_results_df[\"LPF\"]\n",
    "    \n",
    "    w_eff_df = season_results_df[[\"WTeamID\", \"Season\", \"DayNum\", \"WOffEff\", \"WDefEff\"]]\n",
    "    w_eff_df = w_eff_df.rename(columns={\"WTeamID\": \"TeamID\", \"WOffEff\": \"OffEff\", \"WDefEff\": \"DefEff\"})\n",
    "    \n",
    "    l_eff_df = season_results_df[[\"LTeamID\", \"Season\", \"DayNum\", \"LOffEff\", \"LDefEff\"]]\n",
    "    l_eff_df = l_eff_df.rename(columns={\"LTeamID\": \"TeamID\", \"LOffEff\": \"OffEff\", \"LDefEff\": \"DefEff\"})\n",
    "    \n",
    "    eff_df = pd.concat([w_eff_df, l_eff_df]).sort_values(by=[\"Season\", \"DayNum\"]).reset_index(drop=True)\n",
    "    \n",
    "    eff_df.drop([\"DayNum\"], axis=1, inplace=True)\n",
    "    \n",
    "    eff_df = eff_df.groupby(by=[\"Season\", \"TeamID\"]).agg(\"mean\").reset_index()\n",
    "    \n",
    "    return eff_df\n",
    "    \n",
    "print(get_efficiency(m_regular_season_detailed_results_df))\n",
    "\n",
    "def get_rankings(rankings_df):\n",
    "    rankings_df = rankings_df.copy()\n",
    "    \n",
    "    rankings_df = rankings_df[rankings_df[\"RankingDayNum\"] == 133].reset_index(drop=True)\n",
    "    \n",
    "    mean_median_rankings_df = rankings_df.groupby([\"Season\", \"TeamID\"])[[\"OrdinalRank\"]].agg([(\"MeanOrdinalRank\", \"mean\"), (\"MedianOrdinalRank\", \"median\")])\n",
    "    mean_median_rankings_df.columns = mean_median_rankings_df.columns.droplevel(0)\n",
    "    mean_median_rankings_df = mean_median_rankings_df.reset_index()\n",
    "    \n",
    "    massey_rankings_df = rankings_df[rankings_df[\"SystemName\"] == \"MAS\"].reset_index(drop=True)\n",
    "    massey_rankings_df = massey_rankings_df.rename(columns={\"OrdinalRank\": \"MasseyOrdinalRank\"})\n",
    "    massey_rankings_df = massey_rankings_df[[\"Season\", \"TeamID\", \"MasseyOrdinalRank\"]].reset_index(drop=True)\n",
    "    \n",
    "    rankings_df = pd.merge(mean_median_rankings_df, massey_rankings_df, on=[\"Season\", \"TeamID\"], how=\"left\")\n",
    "    \n",
    "    return rankings_df\n",
    "    \n",
    "print(get_rankings(m_massey_ordinals_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ID  Season  TeamID_1  TeamID_2  Result\n",
      "0      2015_1103_1420    2015      1103      1420       1\n",
      "1      2015_1104_1406    2015      1104      1406       1\n",
      "2      2015_1112_1291    2015      1112      1291       1\n",
      "3      2015_1113_1152    2015      1113      1152       1\n",
      "4      2015_1119_1102    2015      1119      1102       1\n",
      "...               ...     ...       ...       ...     ...\n",
      "53967  2019_1222_1153    2019      1222      1153       0\n",
      "53968  2019_1426_1209    2019      1426      1209       0\n",
      "53969  2019_1276_1277    2019      1276      1277       0\n",
      "53970  2019_1382_1387    2019      1382      1387       0\n",
      "53971  2019_1217_1463    2019      1217      1463       0\n",
      "\n",
      "[53972 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def prep_season(season_results_df):\n",
    "    season_results_df = season_results_df.copy()\n",
    "    \n",
    "    seasons = season_results_df[\"Season\"]\n",
    "    season_min_gt = seasons > 2014\n",
    "    season_max_lt = seasons < 2020\n",
    "    all_teams_df = season_results_df[season_min_gt & season_max_lt].reset_index(drop=True)\n",
    "    \n",
    "    w_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    w_teams_df = w_teams_df.rename(columns={\"WTeamID\": \"TeamID_1\", \"LTeamID\": \"TeamID_2\"})\n",
    "    w_teams_df[\"Result\"] = 1\n",
    "    \n",
    "    l_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    l_teams_df = l_teams_df.rename(columns={\"WTeamID\": \"TeamID_2\", \"LTeamID\": \"TeamID_1\"})\n",
    "    l_teams_df[\"Result\"] = 0\n",
    "    \n",
    "    all_teams_df = pd.concat([w_teams_df, l_teams_df]).reset_index(drop=True)\n",
    "    \n",
    "    all_teams_df[\"ID\"] = all_teams_df[\"Season\"].apply(str) + \"_\" + all_teams_df[\"TeamID_1\"].apply(str) + \"_\" + all_teams_df[\"TeamID_2\"].apply(str)\n",
    "    \n",
    "    all_teams_df = all_teams_df[[\"ID\", \"Season\", \"TeamID_1\", \"TeamID_2\", \"Result\"]]\n",
    "    \n",
    "    return all_teams_df\n",
    "    \n",
    "print(prep_season(m_regular_season_compact_results_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_predictions(sample_output_df, ncaa_tourney_results_df):\n",
    "    features_df = sample_output_df.copy()\n",
    "    features_df[\"Season\"] = features_df[\"ID\"].apply(lambda row: int(row[:4]))\n",
    "    features_df[\"TeamID_1\"] = features_df[\"ID\"].apply(lambda row: int(row[5:9]))\n",
    "    features_df[\"TeamID_2\"] = features_df[\"ID\"].apply(lambda row: int(row[10:14]))\n",
    "    features_df.drop([\"Pred\"], axis=1, inplace=True)\n",
    "    \n",
    "    ncaa_tourney_results_df = ncaa_tourney_results_df.copy()\n",
    "    seasons = ncaa_tourney_results_df[\"Season\"]\n",
    "    season_min_gt = seasons > 2014\n",
    "    season_max_lt = seasons < 2020\n",
    "    all_teams_df = ncaa_tourney_results_df[season_min_gt & season_max_lt].reset_index(drop=True)\n",
    "    \n",
    "    w_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    w_teams_df = w_teams_df.rename(columns={\"WTeamID\": \"TeamID_1\", \"LTeamID\": \"TeamID_2\"})\n",
    "    w_teams_df[\"Result\"] = 1\n",
    "    \n",
    "    l_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    l_teams_df = l_teams_df.rename(columns={\"WTeamID\": \"TeamID_2\", \"LTeamID\": \"TeamID_1\"})\n",
    "    l_teams_df[\"Result\"] = 0\n",
    "    \n",
    "    all_teams_df = pd.concat([w_teams_df, l_teams_df]).reset_index(drop=True)\n",
    "    \n",
    "    features_df = features_df.merge(all_teams_df, on=[\"Season\", \"TeamID_1\", \"TeamID_2\"], how=\"left\")\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_features(features_df, ppg_df, eff_df, rankings_df):\n",
    "    features_df = features_df.copy()\n",
    "    ppg_df = ppg_df.copy()\n",
    "    eff_df = eff_df.copy()\n",
    "    rankings_df = rankings_df.copy()\n",
    "    \n",
    "    w_ppg_df = ppg_df.rename(columns={\"PPG\": \"PPG_1\", \"WPerc\": \"WPerc_1\"})\n",
    "    l_ppg_df = ppg_df.rename(columns={\"PPG\": \"PPG_2\", \"WPerc\": \"WPerc_2\"})\n",
    "    \n",
    "    features_df = pd.merge(features_df, w_ppg_df, left_on=[\"Season\", \"TeamID_1\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\", \"Games\"], axis=1, inplace=True)\n",
    "    features_df = pd.merge(features_df, l_ppg_df, left_on=[\"Season\", \"TeamID_2\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\", \"Games\"], axis=1, inplace=True)\n",
    "    \n",
    "    w_eff_df = eff_df.rename(columns={\"OffEff\": \"OffEff_1\", \"DefEff\": \"DefEff_1\"})\n",
    "    l_eff_df = eff_df.rename(columns={\"OffEff\": \"OffEff_2\", \"DefEff\": \"DefEff_2\"})\n",
    "    \n",
    "    features_df = pd.merge(features_df, w_eff_df, left_on=[\"Season\", \"TeamID_1\"], right_on=[\"Season\", \"TeamID\"], how=\"left\")#.reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    features_df = pd.merge(features_df, l_eff_df, left_on=[\"Season\", \"TeamID_2\"], right_on=[\"Season\", \"TeamID\"], how=\"left\")#.reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    \n",
    "    features_df[\"PPGDiff\"] = features_df[\"PPG_1\"] - features_df[\"PPG_2\"]\n",
    "    features_df[\"WPercDiff\"] = features_df[\"WPerc_1\"] - features_df[\"WPerc_2\"]\n",
    "    features_df[\"OffEffDiff\"] = features_df[\"OffEff_1\"] - features_df[\"OffEff_2\"]\n",
    "    features_df[\"DefEffDiff\"] = features_df[\"DefEff_1\"] - features_df[\"DefEff_2\"]\n",
    "    features_df.drop([\"PPG_1\", \"PPG_2\", \"WPerc_1\", \"WPerc_2\", \"OffEff_1\", \"OffEff_2\", \"DefEff_1\", \"DefEff_2\"], axis=1, inplace=True)\n",
    "    \n",
    "    w_rankings_df = rankings_df.rename(columns={\"MeanOrdinalRank\": \"MeanOrdinalRank_1\", \"MedianOrdinalRank\": \"MedianOrdinalRank_1\", \"MasseyOrdinalRank\": \"MasseyOrdinalRank_1\"})\n",
    "    l_rankings_df = rankings_df.rename(columns={\"MeanOrdinalRank\": \"MeanOrdinalRank_2\", \"MedianOrdinalRank\": \"MedianOrdinalRank_2\", \"MasseyOrdinalRank\": \"MasseyOrdinalRank_2\"})\n",
    "    \n",
    "    features_df = pd.merge(features_df, w_rankings_df, left_on=[\"Season\", \"TeamID_1\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    features_df = pd.merge(features_df, l_rankings_df, left_on=[\"Season\", \"TeamID_2\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    \n",
    "    features_df[\"MeanOrdinalRankDiff\"] = features_df[\"MeanOrdinalRank_1\"] - features_df[\"MeanOrdinalRank_2\"]\n",
    "    features_df[\"MedianOrdinalRankDiff\"] = features_df[\"MedianOrdinalRank_1\"] - features_df[\"MedianOrdinalRank_2\"]\n",
    "    features_df[\"MasseyOrdinalRankDiff\"] = features_df[\"MasseyOrdinalRank_1\"] - features_df[\"MasseyOrdinalRank_2\"]\n",
    "    features_df.drop([\"MeanOrdinalRank_1\", \"MeanOrdinalRank_2\", \"MedianOrdinalRank_1\", \"MedianOrdinalRank_2\", \"MasseyOrdinalRank_1\", \"MasseyOrdinalRank_2\"], axis=1, inplace=True)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = prepare_predictions(hist_sample_subm_df, m_ncaa_tourney_compact_results_df)\n",
    "ppg_df = get_ppg(m_regular_season_compact_results_df)\n",
    "eff_df = get_efficiency(m_regular_season_detailed_results_df)\n",
    "rankings_df = get_rankings(m_massey_ordinals_df)\n",
    "tourney_df = merge_features(features_df, ppg_df, eff_df, rankings_df)\n",
    "\n",
    "train_features_df = prep_season(m_regular_season_compact_results_df)\n",
    "reg_season_df = merge_features(train_features_df, ppg_df, eff_df, rankings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = reg_season_df[[\n",
    "    \"PPGDiff\", \"WPercDiff\", \"OffEffDiff\", \"DefEffDiff\",\n",
    "    \"MeanOrdinalRankDiff\",\"MedianOrdinalRankDiff\", \"MasseyOrdinalRankDiff\"\n",
    "]]\n",
    "y_train = reg_season_df[[\"Result\"]]\n",
    "\n",
    "tourney_actuals_df = tourney_df.copy().dropna()\n",
    "x_test = tourney_actuals_df[[\n",
    "    \"PPGDiff\", \"WPercDiff\", \"OffEffDiff\", \"DefEffDiff\",\n",
    "    \"MeanOrdinalRankDiff\",\"MedianOrdinalRankDiff\", \"MasseyOrdinalRankDiff\"\n",
    "]]\n",
    "y_test = tourney_actuals_df[[\"Result\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, verbose=1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "log_reg = LogisticRegression(penalty=\"l2\", random_state=None, max_iter=1000, verbose=1)\n",
    "\n",
    "log_reg.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5652996256814534\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))\n",
    "\n",
    "y_pred = log_reg.predict_proba(\n",
    "    tourney_df[[\n",
    "        \"PPGDiff\", \"WPercDiff\", \"OffEffDiff\", \"DefEffDiff\",\n",
    "        \"MeanOrdinalRankDiff\",\"MedianOrdinalRankDiff\", \"MasseyOrdinalRankDiff\"\n",
    "    ]]\n",
    ")\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "# print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))\n",
    "\n",
    "stage_1_submission_df = tourney_df[[\"ID\"]].copy()\n",
    "stage_1_submission_df[\"Pred\"] = y_pred\n",
    "stage_1_submission_df.to_csv(\"brady_lange_m_submission_stage_01.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
