{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021 March Madness Bracket Predictor\n",
    "\n",
    "### Predicts and generates a 2021 March Madness bracket.\n",
    "\n",
    "Developers:\n",
    "- Brady Lange (03/17/2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configure settings\n",
    "# pd.set_option(\"display.max.columns\", None)\n",
    "# pd.set_option(\"display.max.rows\", None)\n",
    "# pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Pathing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.abspath(\"..\")\n",
    "data_path = os.path.join(base_path, \"data\")\n",
    "output_path = os.path.join(data_path, \"output_data\")\n",
    "\n",
    "m_subm_stage_1_output_path = os.path.join(output_path, \"m_submission_stage_1.csv\")\n",
    "m_subm_stage_2_output_path = os.path.join(output_path, \"m_submission_stage_2.csv\")\n",
    "\n",
    "data_file_paths = {}\n",
    "exclude_dirs = [\"initial_data\", \"ncaa_march_madness_2020_data\", \"MDataFiles_Stage1\"]\n",
    "\n",
    "for root, dirs, files in os.walk(data_path, topdown=True):\n",
    "    # Exclude last year's challenge data\n",
    "    dirs[:] = [d for d in dirs if d not in exclude_dirs]\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            data_file_paths[file_name[:-4]] = os.path.join(root, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data\n",
    "m_ncaa_tourney_compact_results_df = pd.read_csv(data_file_paths[\"MNCAATourneyCompactResults\"])\n",
    "m_ncaa_tourney_seeds_df = pd.read_csv(data_file_paths[\"MNCAATourneySeeds\"])\n",
    "m_regular_season_compact_results_df = pd.read_csv(data_file_paths[\"MRegularSeasonCompactResults\"])\n",
    "m_seasons_df = pd.read_csv(data_file_paths[\"MSeasons\"])\n",
    "m_teams_df = pd.read_csv(data_file_paths[\"MTeams\"])\n",
    "\n",
    "# Team box scores data\n",
    "m_ncaa_tourney_detailed_results_df = pd.read_csv(data_file_paths[\"MNCAATourneyDetailedResults\"])\n",
    "m_regular_season_detailed_results_df = pd.read_csv(data_file_paths[\"MRegularSeasonDetailedResults\"])\n",
    "\n",
    "# Geography data\n",
    "cities_df = pd.read_csv(data_file_paths[\"Cities\"])\n",
    "m_game_cities_df = pd.read_csv(data_file_paths[\"MGameCities\"])\n",
    "\n",
    "# Public rankings data\n",
    "m_massey_ordinals_df = pd.read_csv(data_file_paths[\"MMasseyOrdinals\"])\n",
    "\n",
    "# Supplemental data\n",
    "conferences_df = pd.read_csv(data_file_paths[\"Conferences\"])\n",
    "m_conference_tourney_games_df = pd.read_csv(data_file_paths[\"MConferenceTourneyGames\"])\n",
    "m_ncaa_tourney_seed_round_slots_df = pd.read_csv(data_file_paths[\"MNCAATourneySeedRoundSlots\"])\n",
    "m_ncaa_tourney_slots_df = pd.read_csv(data_file_paths[\"MNCAATourneySlots\"])\n",
    "m_secondary_tourney_compact_results_df = pd.read_csv(data_file_paths[\"MSecondaryTourneyCompactResults\"])\n",
    "m_secondary_tourney_teams_df = pd.read_csv(data_file_paths[\"MSecondaryTourneyTeams\"])\n",
    "m_team_coaches_df = pd.read_csv(data_file_paths[\"MTeamCoaches\"])\n",
    "m_team_conferences_df = pd.read_csv(data_file_paths[\"MTeamConferences\"])\n",
    "# Windows codepage 1252 encoded file\n",
    "m_team_spellings_df = pd.read_csv(data_file_paths[\"MTeamSpellings\"], encoding=\"cp1252\")\n",
    "\n",
    "# External data\n",
    "m_ncaa_bpi_21_df = pd.read_csv(data_file_paths[\"m_ncaa_bpi_2021\"])\n",
    "\n",
    "# Sample submission data\n",
    "hist_sample_subm_df = pd.read_csv(data_file_paths[\"MSampleSubmissionStage1\"])\n",
    "sample_subm_df = pd.read_csv(data_file_paths[\"MSampleSubmissionStage2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_df(df, title=\"Data Frame\"):\n",
    "    \"\"\"\n",
    "    Explores a specified Pandas data frame by printing out all of it's metrics\n",
    "    and information neatly.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): Pandas Data Frame to explore.\n",
    "        title (str): Title/name of data frame. Default is 'Data Frame'.\n",
    "        \n",
    "    Returns:\n",
    "        None: Nothing.\n",
    "    \"\"\"\n",
    "    print(\"======================================================================\")\n",
    "    print(\"{0}:\".format(title))\n",
    "    print(\"======================================================================\")\n",
    "    print(\"Data Type:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(type(df), \"\\n\")\n",
    "    print(\"First 5 Rows:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.head(), \"\\n\")\n",
    "    print(\"Last 5 Rows:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.tail(), \"\\n\")\n",
    "    print(\"Description:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.describe(include=np.object), \"\\n\")\n",
    "    print(\"Information:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    df.info()\n",
    "    print(\"\\nNumber of Rows & Columns (Rows, Columns):\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.shape, \"\\n\")\n",
    "    print(\"Number of Rows:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(len(df), \"\\n\")\n",
    "    print(\"Number of Elements (Rows x Columns):\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.size, \"\\n\")\n",
    "    print(\"Columns:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.columns, \"\\n\")\n",
    "    for column in df.columns:\n",
    "        print(\"Column:\")\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        print(column, \"\\n\")\n",
    "        print(\"'{0}' Value Counts:\".format(column))\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        print(df[column].value_counts(), \"\\n\")\n",
    "        print(\"Minimum '{0}' Value:\".format(column))\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        print(df[column].min(), \"\\n\")\n",
    "        print(\"Maximum '{0}' Value:\".format(column))\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        print(df[column].max(), \"\\n\")\n",
    "    print(\"Null Values:\")\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(df.isnull().sum(), \"\\n\")\n",
    "\n",
    "# Basic data\n",
    "explore_df(df=m_ncaa_tourney_compact_results_df, title=\"Men's NCAA Tourney Compact Results\")\n",
    "explore_df(df=m_ncaa_tourney_seeds_df, title=\"Men's NCAA Tourney Seeds\")\n",
    "explore_df(df=m_regular_season_compact_results_df, title=\"Men's Regular Season Compact Results\")\n",
    "explore_df(df=m_seasons_df, title=\"Men's Seasons\")\n",
    "explore_df(df=m_teams_df, title=\"Men's Teams\")\n",
    "\n",
    "# Team box scores data\n",
    "explore_df(df=m_ncaa_tourney_detailed_results_df, title=\"Men's NCAA Tourney Detailed Results\")\n",
    "explore_df(df=m_regular_season_detailed_results_df, title=\"Men's Regular Season Detailed Results\")\n",
    "\n",
    "# Geography data\n",
    "explore_df(df=cities_df, title=\"Cities\")\n",
    "explore_df(df=m_game_cities_df, title=\"Men's Game Cities\")\n",
    "\n",
    "# Public rankings data\n",
    "explore_df(df=m_massey_ordinals_df, title=\"Men's Massey Ordinals\")\n",
    "\n",
    "# Supplemental data\n",
    "explore_df(df=conferences_df, title=\"Conferences\")\n",
    "explore_df(df=m_conference_tourney_games_df, title=\"Men's Conference Tourney Games\")\n",
    "explore_df(df=m_ncaa_tourney_seed_round_slots_df, title=\"Men's NCAA Tourney Seed Round Slots\")\n",
    "explore_df(df=m_ncaa_tourney_slots_df, title=\"Men's NCAA Tourney Slots\")\n",
    "explore_df(df=m_secondary_tourney_compact_results_df, title=\"Men's Secondary Tourney Compact Results\")\n",
    "explore_df(df=m_secondary_tourney_teams_df, title=\"Men's Secondary Tourney Teams\")\n",
    "explore_df(df=m_team_coaches_df, title=\"Men's Team Coaches\")\n",
    "explore_df(df=m_team_conferences_df, title=\"Men's Team Conferences\")\n",
    "explore_df(df=m_team_spellings_df, title=\"Men's Team Spellings\")\n",
    "\n",
    "all_game_compact_results_df = pd.concat([m_ncaa_tourney_compact_results_df, m_regular_season_compact_results_df])\n",
    "all_game_detailed_results_df = pd.concat([m_ncaa_tourney_detailed_results_df, m_regular_season_detailed_results_df])\n",
    "\n",
    "df = m_ncaa_tourney_compact_results_df.merge(\n",
    "    m_teams_df[[\"TeamID\", \"TeamName\"]], left_on=\"WTeamID\", right_on=\"TeamID\", validate=\"many_to_one\"\n",
    ").drop(\n",
    "    \"TeamID\", axis=1\n",
    ").rename(\n",
    "    columns={\"TeamName\": \"WTeamName\"}\n",
    ").merge(\n",
    "    m_teams_df[[\"TeamID\", \"TeamName\"]], left_on=\"LTeamID\", right_on=\"TeamID\"\n",
    ").drop(\n",
    "    \"TeamID\", axis=1\n",
    ").rename(\n",
    "    columns={\"TeamName\": \"LTeamName\"}\n",
    ")\n",
    "df\n",
    "\n",
    "df = all_game_detailed_results_df.merge(\n",
    "    m_teams_df[[\"TeamID\", \"TeamName\"]], left_on=\"WTeamID\", right_on=\"TeamID\", validate=\"many_to_one\"\n",
    ").drop(\n",
    "    \"TeamID\", axis=1\n",
    ").rename(\n",
    "    columns={\"TeamName\": \"WTeamName\"}\n",
    ").merge(\n",
    "    m_teams_df[[\"TeamID\", \"TeamName\"]], left_on=\"LTeamID\", right_on=\"TeamID\"\n",
    ").drop(\n",
    "    \"TeamID\", axis=1\n",
    ").rename(\n",
    "    columns={\"TeamName\": \"LTeamName\"}\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ncaa_bpi_21_df[\"TEAM\"] = m_ncaa_bpi_21_df[\"TEAM\"].str.lower()\n",
    "\n",
    "m_ncaa_bpi_21_df = pd.merge(m_ncaa_bpi_21_df, m_team_spellings_df, left_on=\"TEAM\", right_on=\"TeamNameSpelling\", how=\"inner\")\n",
    "m_ncaa_bpi_21_df.drop([\"RPI RK\", \"TeamNameSpelling\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOSSARY\n",
    "# BPI RK: Rank in the Basketball Power Index (BPI) among all Division I teams.\n",
    "# SOS RK: Strength of Schedule (SOS) rank among all Division I teams based on how a typical 25th ranked team would do against each team's schedule to date. SOS accounts for the game location, day's rest, travel distance, and high altitude in addition to opponent strength.\n",
    "# SOR RK: Rank of Strength of Record (SOR) among all Division I teams. SOR reflects the chance a typical 25th ranked team would have team's record or better, given the schedule on a 0 to 100 scale, where 100 is best.\n",
    "# RPI RK: Team's rank in official NCAA Ratings Percentage Index (RPI).\n",
    "# https://www.espn.com/mens-college-basketball/bpi/_/view/overview/page/1\n",
    "\n",
    "def get_bpi(bpi_df):\n",
    "    bpi_df = bpi_df.copy()\n",
    "    \n",
    "    bpi_df.drop([\"RK\", \"TEAM\", \"CONF\", \"W-L\", \"SOS RK\", \"SOR RK\"], axis=1, inplace=True)\n",
    "    \n",
    "    bpi_df = bpi_df[[\"TeamID\", \"Season\", \"BPI RK\"]].sort_values(by=\"TeamID\").reset_index(drop=True)\n",
    "    \n",
    "    return bpi_df\n",
    "\n",
    "def get_sos(sos_df):\n",
    "    sos_df = sos_df.copy()\n",
    "    \n",
    "    sos_df.drop([\"RK\", \"TEAM\", \"CONF\", \"W-L\", \"BPI RK\", \"SOR RK\"], axis=1, inplace=True)\n",
    "    \n",
    "    sos_df = sos_df[[\"TeamID\", \"Season\", \"SOS RK\"]].sort_values(by=\"TeamID\").reset_index(drop=True)\n",
    "    \n",
    "    return sos_df\n",
    "\n",
    "def get_sor(sor_df):\n",
    "    sor_df = sor_df.copy()\n",
    "    \n",
    "    sor_df.drop([\"RK\", \"TEAM\", \"CONF\", \"W-L\", \"BPI RK\", \"SOS RK\"], axis=1, inplace=True)\n",
    "    \n",
    "    sor_df = sor_df[[\"TeamID\", \"Season\", \"SOR RK\"]].sort_values(by=\"TeamID\").reset_index(drop=True)\n",
    "    \n",
    "    return sor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TeamID  Season        PPG     WPerc  Games\n",
      "0        1102    1985  63.083333  0.208333     24\n",
      "1        1103    1985  61.043478  0.391304     23\n",
      "2        1104    1985  68.318519  0.700000     30\n",
      "3        1106    1985  71.625000  0.416667     24\n",
      "4        1108    1985  83.000000  0.760000     25\n",
      "...       ...     ...        ...       ...    ...\n",
      "11936    1312    2008  55.931034  0.000000     29\n",
      "11937    1212    2013  49.678571  0.000000     28\n",
      "11938    1212    2015  51.111111  0.000000     27\n",
      "11939    1363    2015  52.265873  0.000000     28\n",
      "11940    1152    2021  55.444444  0.000000      9\n",
      "\n",
      "[11941 rows x 5 columns]\n",
      "       Season  WTeamID  LTeamID  WPPGAgainstTeam  LPPGAgainstTeam  \\\n",
      "0        1985     1102     1140        82.000000        79.000000   \n",
      "1        1985     1102     1218        58.000000        54.000000   \n",
      "2        1985     1102     1461        52.000000        49.000000   \n",
      "3        1985     1103     1122        80.000000        66.000000   \n",
      "4        1985     1103     1184        88.000000        86.000000   \n",
      "...       ...      ...      ...              ...              ...   \n",
      "40157    2021     1470     1308        64.000000        55.000000   \n",
      "40158    2021     1470     1430        70.000000        62.000000   \n",
      "40159    2021     1470     1469        77.000000        59.000000   \n",
      "40160    2021     1471     1413        89.000000        69.000000   \n",
      "40161    2021     1471     1415        73.777778        72.888889   \n",
      "\n",
      "       GamesAgainstTeam  WPercAgainstTeam  WLPercAgainstTeam  \n",
      "0                     3          0.333333           0.666667  \n",
      "1                     2          0.500000           0.500000  \n",
      "2                     2          0.500000           0.500000  \n",
      "3                     2          0.500000           0.500000  \n",
      "4                     2          0.500000           0.500000  \n",
      "...                 ...               ...                ...  \n",
      "40157                 2          0.500000           0.500000  \n",
      "40158                 2          0.500000           0.500000  \n",
      "40159                 2          0.500000           0.500000  \n",
      "40160                 2          0.500000           0.500000  \n",
      "40161                 3          0.333333           0.666667  \n",
      "\n",
      "[40162 rows x 8 columns]\n",
      "       TeamID_1  TeamID_2  WPPGAllTime_1  LPPGAllTime_1  WPercAllTime_1  \\\n",
      "0          1101      1117      94.000000          69.00        0.500000   \n",
      "1          1101      1146      75.358025          75.75        0.692308   \n",
      "2          1101      1149      75.555556          65.00        0.500000   \n",
      "3          1101      1170      72.000000          68.80        0.500000   \n",
      "4          1101      1223      80.333333          68.00        0.750000   \n",
      "...         ...       ...            ...            ...             ...   \n",
      "19037      1308      1470      78.000000          51.00        0.500000   \n",
      "19038      1430      1470      73.000000          60.00        0.500000   \n",
      "19039      1469      1470      64.000000          48.00        0.500000   \n",
      "19040      1413      1471      78.000000          71.00        0.500000   \n",
      "19041      1415      1471      76.000000          67.00        0.500000   \n",
      "\n",
      "       LPercAllTime_1  WPPGAllTime_2  LPPGAllTime_2  WPercAllTime_2  \\\n",
      "0            0.500000      83.000000      73.000000        0.500000   \n",
      "1            0.307692      80.750000      62.925926        0.307692   \n",
      "2            0.500000      66.000000      72.888889        0.500000   \n",
      "3            0.500000      70.400000      61.000000        0.500000   \n",
      "4            0.250000      77.000000      69.222222        0.250000   \n",
      "...               ...            ...            ...             ...   \n",
      "19037        0.500000      64.000000      55.000000        0.500000   \n",
      "19038        0.500000      70.000000      62.000000        0.500000   \n",
      "19039        0.500000      77.000000      59.000000        0.500000   \n",
      "19040        0.500000      89.000000      69.000000        0.500000   \n",
      "19041        0.500000      73.777778      72.888889        0.250000   \n",
      "\n",
      "       LPercAllTime_2  WLGamesAllTime  \n",
      "0            0.500000               2  \n",
      "1            0.692308              13  \n",
      "2            0.500000               2  \n",
      "3            0.500000               2  \n",
      "4            0.750000              12  \n",
      "...               ...             ...  \n",
      "19037        0.500000               2  \n",
      "19038        0.500000               2  \n",
      "19039        0.500000               2  \n",
      "19040        0.500000               2  \n",
      "19041        0.250000               4  \n",
      "\n",
      "[19042 rows x 11 columns]\n",
      "      Season  TeamID      OffEff      DefEff\n",
      "0       2003    1102   74.428571  115.821429\n",
      "1       2003    1103  100.188477  135.788477\n",
      "2       2003    1104   94.599206  147.968254\n",
      "3       2003    1105   97.922222  153.617094\n",
      "4       2003    1106   87.134921  148.186508\n",
      "...      ...     ...         ...         ...\n",
      "6529    2021    1467   83.302469  137.407407\n",
      "6530    2021    1468   94.500000  121.722222\n",
      "6531    2021    1469   89.736842  138.210526\n",
      "6532    2021    1470   79.600000  128.466667\n",
      "6533    2021    1471   88.841270  125.579365\n",
      "\n",
      "[6534 rows x 4 columns]\n",
      "      Season  TeamID  MeanOrdinalRank  MedianOrdinalRank  MasseyOrdinalRank\n",
      "0       2003    1102       156.031250              156.0              172.0\n",
      "1       2003    1103       168.000000              170.5              163.0\n",
      "2       2003    1104        38.031250               37.0               41.0\n",
      "3       2003    1105       308.968750              310.0              310.0\n",
      "4       2003    1106       262.687500              265.5              270.0\n",
      "...      ...     ...              ...                ...                ...\n",
      "6175    2021    1467       239.530612              241.0              292.0\n",
      "6176    2021    1468       180.729167              179.5              195.0\n",
      "6177    2021    1469       314.893617              317.0              315.0\n",
      "6178    2021    1470       254.361702              255.0              250.0\n",
      "6179    2021    1471       255.708333              254.5              265.0\n",
      "\n",
      "[6180 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering Ideas:\n",
    "# - Feature engineer PPG, other metrics against opposing team per season [*PPG done]\n",
    "# - Feature engineer PPG, other metrics against opposing team all-time [*PPG done]\n",
    "# - Feature engineer data from people's bracket picks []\n",
    "# - Feature engineer PPG, wins, other metrics against ranked opponents [*]\n",
    "# - Feature engineer amount players with top stats for each team https://www.ncaa.com/stats/basketball-men/d1 []\n",
    "# Features to consider:\n",
    "# - https://www.sportsbettingdime.com/guides/strategy/7-attributes-of-march-madness-winners/\n",
    "# - https://www.espn.com/mens-college-basketball/bpi\n",
    "\n",
    "GAME_MINS = 40\n",
    "OT_MINS = 5\n",
    "\n",
    "def get_ppg(season_results_df):    \n",
    "    season_results_df = season_results_df.copy()\n",
    "    \n",
    "    season_results_df[\"GameDuration\"] = GAME_MINS + OT_MINS * season_results_df[\"NumOT\"]\n",
    "    \n",
    "    season_results_df[\"WTeamPPG\"] = (season_results_df[\"WScore\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LTeamPPG\"] = (season_results_df[\"LScore\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    w_team_ppg = season_results_df[[\"Season\", \"WTeamID\", \"WTeamPPG\"]]\n",
    "    w_team_ppg = w_team_ppg.groupby([\"Season\", \"WTeamID\"]).agg([(\"WPPG\", \"mean\"), (\"WGames\", \"count\")])\n",
    "    w_team_ppg.columns = w_team_ppg.columns.droplevel(0)\n",
    "    w_team_ppg = w_team_ppg.reset_index()\n",
    "    \n",
    "    l_team_ppg = season_results_df[[\"Season\", \"LTeamID\", \"LTeamPPG\"]]\n",
    "    l_team_ppg = l_team_ppg.groupby([\"Season\", \"LTeamID\"]).agg([(\"LPPG\", \"mean\"), (\"LGames\", \"count\")])\n",
    "    l_team_ppg.columns = l_team_ppg.columns.droplevel(0)\n",
    "    l_team_ppg = l_team_ppg.reset_index()\n",
    "    \n",
    "    ppg_df = pd.merge(w_team_ppg, l_team_ppg, left_on=[\"Season\", \"WTeamID\"], right_on=[\"Season\", \"LTeamID\"], how=\"outer\")\n",
    "    \n",
    "    ppg_df = ppg_df.fillna({\"WTeamID\": ppg_df[\"LTeamID\"], \"WPPG\": 0, \"WGames\": 0, \"LTeamID\": ppg_df[\"WTeamID\"], \"LPPG\": 0, \"LGames\": 0})\n",
    "    \n",
    "    ppg_df[\"PPG\"] = (ppg_df[\"WPPG\"] * ppg_df[\"WGames\"] + ppg_df[\"LPPG\"] * ppg_df[\"LGames\"]) / (ppg_df[\"WGames\"] + ppg_df[\"LGames\"])\n",
    "    ppg_df[\"WPerc\"] = ppg_df[\"WGames\"] / (ppg_df[\"WGames\"] + ppg_df[\"LGames\"])\n",
    "    ppg_df[\"Games\"] = (ppg_df[\"WGames\"] + ppg_df[\"LGames\"]).astype(int)\n",
    "    \n",
    "    ppg_df[\"TeamID\"] = ppg_df[\"WTeamID\"].astype(int)\n",
    "    \n",
    "    ppg_df.drop([\"WTeamID\", \"WPPG\", \"WGames\", \"LTeamID\", \"LPPG\", \"LGames\"], axis=1, inplace=True)\n",
    "    \n",
    "    ppg_df = ppg_df[[\"TeamID\", \"Season\", \"PPG\", \"WPerc\", \"Games\"]]\n",
    "    \n",
    "    return ppg_df\n",
    "    \n",
    "print(get_ppg(m_regular_season_compact_results_df))\n",
    "\n",
    "def get_ppg_vs_team_season(season_results_df):\n",
    "    season_results_df = season_results_df.copy()\n",
    "    \n",
    "    season_results_df[\"GameDuration\"] = GAME_MINS + OT_MINS * season_results_df[\"NumOT\"]\n",
    "    \n",
    "    season_results_df[\"WTeamScoreNorm\"] = (season_results_df[\"WScore\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LTeamScoreNorm\"] = (season_results_df[\"LScore\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    team_vs_ppg = season_results_df[[\"Season\", \"WTeamID\", \"WTeamScoreNorm\", \"LTeamID\", \"LTeamScoreNorm\"]]\n",
    "    team_vs_ppg = team_vs_ppg.groupby([\"Season\", \"WTeamID\", \"LTeamID\"]).agg({\"WTeamScoreNorm\": [(\"WPPGAgainstTeam\", \"mean\"), (\"WGames\", \"count\")], \"LTeamScoreNorm\": [(\"LPPGAgainstTeam\", \"mean\")]})\n",
    "    team_vs_ppg.columns = team_vs_ppg.columns.droplevel(0)\n",
    "    team_vs_ppg = team_vs_ppg.reset_index()\n",
    "    \n",
    "    team_vs_ppg = pd.merge(team_vs_ppg, team_vs_ppg[[\"Season\", \"WTeamID\", \"LTeamID\", \"WGames\"]], left_on=[\"Season\", \"WTeamID\", \"LTeamID\"], right_on=[\"Season\", \"LTeamID\", \"WTeamID\"], how=\"inner\")\n",
    "    team_vs_ppg.drop([\"WTeamID_y\", \"LTeamID_y\"], axis=1, inplace=True)\n",
    "    team_vs_ppg = team_vs_ppg.rename(columns={\"WTeamID_x\": \"WTeamID\", \"LTeamID_x\": \"LTeamID\", \"WGames_x\": \"WGamesAgainstTeam\", \"WGames_y\": \"WLGamesAgainstTeam\"})\n",
    "\n",
    "    team_vs_ppg[\"GamesAgainstTeam\"] = (team_vs_ppg[\"WGamesAgainstTeam\"] + team_vs_ppg[\"WLGamesAgainstTeam\"]).astype(int)\n",
    "    team_vs_ppg[\"WPercAgainstTeam\"] = team_vs_ppg[\"WGamesAgainstTeam\"] / team_vs_ppg[\"GamesAgainstTeam\"]\n",
    "    team_vs_ppg[\"WLPercAgainstTeam\"] = team_vs_ppg[\"WLGamesAgainstTeam\"] / team_vs_ppg[\"GamesAgainstTeam\"]\n",
    "    \n",
    "    team_vs_ppg.drop([\"WGamesAgainstTeam\", \"WLGamesAgainstTeam\"], axis=1, inplace=True)\n",
    "    \n",
    "#     team_vs_ppg = team_vs_ppg[[\"WTeamID\", \"LTeamID\", \"Season\", \"WPPGAgainstTeam\", \"WPercAgainstTeam\", \"WLPercAgainstTeam\" \"LPPGAgainstTeam\", GamesAgainstTeam\"]]\n",
    "    \n",
    "    return team_vs_ppg\n",
    "\n",
    "print(get_ppg_vs_team_season(m_regular_season_compact_results_df))\n",
    "\n",
    "def get_ppg_vs_team_all_time(season_results_df):\n",
    "    season_results_df = season_results_df.copy()\n",
    "    \n",
    "    season_results_df[\"GameDuration\"] = GAME_MINS + OT_MINS * season_results_df[\"NumOT\"]\n",
    "    \n",
    "    season_results_df[\"WTeamScoreNorm\"] = (season_results_df[\"WScore\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LTeamScoreNorm\"] = (season_results_df[\"LScore\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    team_vs_ppg_all_tm = season_results_df[[\"Season\", \"WTeamID\", \"WTeamScoreNorm\", \"LTeamID\", \"LTeamScoreNorm\"]]\n",
    "    team_vs_ppg_all_tm = team_vs_ppg_all_tm.groupby([\"WTeamID\", \"LTeamID\"]).agg({\"WTeamScoreNorm\": [(\"WPPGAllTime\", \"mean\"), (\"WGamesAllTime\", \"count\")], \"LTeamScoreNorm\": [(\"LPPGAllTime\", \"mean\"), (\"LGamesAllTime\", \"count\")]})\n",
    "    team_vs_ppg_all_tm.columns = team_vs_ppg_all_tm.columns.droplevel(0)\n",
    "    team_vs_ppg_all_tm = team_vs_ppg_all_tm.reset_index()\n",
    "    \n",
    "    team_vs_ppg_all_tm = pd.merge(team_vs_ppg_all_tm, team_vs_ppg_all_tm, left_on=[\"WTeamID\", \"LTeamID\"], right_on=[\"LTeamID\", \"WTeamID\"], how=\"inner\").reset_index(drop=True)\n",
    "    team_vs_ppg_all_tm.drop([\"WTeamID_y\", \"LTeamID_y\"], axis=1, inplace=True)\n",
    "    team_vs_ppg_all_tm = team_vs_ppg_all_tm.rename(\n",
    "        columns={\n",
    "            \"WTeamID_x\": \"TeamID_1\",\n",
    "            \"LTeamID_x\": \"TeamID_2\",\n",
    "            \"WGamesAllTime_x\": \"WGamesAllTime_1\",\n",
    "            \"LGamesAllTime_x\": \"LGamesAllTime_2\",\n",
    "            \"WPPGAllTime_x\": \"WPPGAllTime_1\",\n",
    "            \"LPPGAllTime_x\": \"LPPGAllTime_2\",\n",
    "            \"WGamesAllTime_y\": \"WGamesAllTime_2\",\n",
    "            \"LGamesAllTime_y\": \"LGamesAllTime_1\",\n",
    "            \"WPPGAllTime_y\": \"WPPGAllTime_2\",\n",
    "            \"LPPGAllTime_y\": \"LPPGAllTime_1\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    team_vs_ppg_all_tm.loc[\n",
    "        team_vs_ppg_all_tm[\"TeamID_1\"] > team_vs_ppg_all_tm[\"TeamID_2\"],\n",
    "        [\n",
    "            \"TeamID_1\", \"TeamID_2\", \"WGamesAllTime_1\", \"WGamesAllTime_2\",\n",
    "            \"WPPGAllTime_1\", \"WPPGAllTime_2\", \"WGamesAllTime_2\", \"WGamesAllTime_1\",\n",
    "            \"WPPGAllTime_2\", \"WPPGAllTime_1\"\n",
    "        ]\n",
    "    ] = team_vs_ppg_all_tm.loc[\n",
    "        team_vs_ppg_all_tm[\"TeamID_1\"] > team_vs_ppg_all_tm[\"TeamID_2\"],\n",
    "        [\n",
    "            \"TeamID_2\", \"TeamID_1\", \"WGamesAllTime_2\", \"WGamesAllTime_1\",\n",
    "            \"WPPGAllTime_2\", \"WPPGAllTime_1\", \"WGamesAllTime_1\", \"WGamesAllTime_2\",\n",
    "            \"WPPGAllTime_1\", \"WPPGAllTime_2\"\n",
    "        ]\n",
    "    ].values\n",
    "    \n",
    "    team_vs_ppg_all_tm[\n",
    "        [\"TeamID_1\", \"TeamID_2\", \"WGamesAllTime_1\", \"WGamesAllTime_2\", \"LGamesAllTime_1\", \"LGamesAllTime_2\"]\n",
    "    ] = team_vs_ppg_all_tm[\n",
    "        [\"TeamID_1\", \"TeamID_2\", \"WGamesAllTime_1\", \"WGamesAllTime_2\", \"LGamesAllTime_1\", \"LGamesAllTime_2\"]\n",
    "    ].astype(int)\n",
    "    \n",
    "    team_vs_ppg_all_tm[\"WLGamesAllTime\"] = (team_vs_ppg_all_tm[\"WGamesAllTime_1\"] + team_vs_ppg_all_tm[\"LGamesAllTime_1\"]).astype(int)\n",
    "    team_vs_ppg_all_tm[\"WPercAllTime_1\"] = team_vs_ppg_all_tm[\"WGamesAllTime_1\"] / team_vs_ppg_all_tm[\"WLGamesAllTime\"]\n",
    "    team_vs_ppg_all_tm[\"WPercAllTime_2\"] = team_vs_ppg_all_tm[\"WGamesAllTime_2\"] / team_vs_ppg_all_tm[\"WLGamesAllTime\"]\n",
    "    team_vs_ppg_all_tm[\"LPercAllTime_1\"] = team_vs_ppg_all_tm[\"LGamesAllTime_1\"] / team_vs_ppg_all_tm[\"WLGamesAllTime\"]\n",
    "    team_vs_ppg_all_tm[\"LPercAllTime_2\"] = team_vs_ppg_all_tm[\"LGamesAllTime_2\"] / team_vs_ppg_all_tm[\"WLGamesAllTime\"]\n",
    "    \n",
    "    team_vs_ppg_all_tm = team_vs_ppg_all_tm[\n",
    "        [\n",
    "            \"TeamID_1\", \"TeamID_2\",\n",
    "            \"WPPGAllTime_1\", \"WGamesAllTime_1\", \"LPPGAllTime_1\", \"LGamesAllTime_1\", \"WPercAllTime_1\", \"LPercAllTime_1\",\n",
    "            \"WPPGAllTime_2\", \"WGamesAllTime_2\", \"LPPGAllTime_2\", \"LGamesAllTime_2\", \"WPercAllTime_2\", \"LPercAllTime_2\",\n",
    "            \"WLGamesAllTime\"\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    team_vs_ppg_all_tm.drop(\n",
    "        [\"WGamesAllTime_1\", \"WGamesAllTime_2\", \"LGamesAllTime_1\", \"LGamesAllTime_2\"],\n",
    "        axis=1,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    return team_vs_ppg_all_tm\n",
    "\n",
    "print(get_ppg_vs_team_all_time(m_regular_season_compact_results_df))\n",
    "\n",
    "def get_efficiency(season_results_df):\n",
    "    season_results_df = season_results_df.copy()\n",
    "    \n",
    "    season_results_df[\"GameDuration\"] = GAME_MINS + OT_MINS * season_results_df[\"NumOT\"]\n",
    "    \n",
    "    # Winning teams\n",
    "    # Winning offense\n",
    "    season_results_df[\"WFGM\"] = (season_results_df[\"WFGM\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WFGA\"] = (season_results_df[\"WFGA\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WFGM3\"] = (season_results_df[\"WFGM3\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WFGA3\"] = (season_results_df[\"WFGA3\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WFTM\"] = (season_results_df[\"WFTM\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WFTA\"] = (season_results_df[\"WFTA\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WOR\"] = (season_results_df[\"WOR\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WAst\"] = (season_results_df[\"WAst\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WTO\"] = (season_results_df[\"WTO\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    # Winning defense\n",
    "    season_results_df[\"WDR\"] = (season_results_df[\"WDR\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WStl\"] = (season_results_df[\"WStl\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"WBlk\"] = (season_results_df[\"WBlk\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    # Winning offense & defense\n",
    "    season_results_df[\"WPF\"] = (season_results_df[\"WPF\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    # Losing teams\n",
    "    # Losing offense\n",
    "    season_results_df[\"LFGM\"] = (season_results_df[\"LFGM\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LFGA\"] = (season_results_df[\"LFGA\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LFGM3\"] = (season_results_df[\"LFGM3\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LFGA3\"] = (season_results_df[\"LFGA3\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LFTM\"] = (season_results_df[\"LFTM\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LFTA\"] = (season_results_df[\"LFTA\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LOR\"] = (season_results_df[\"LOR\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LAst\"] = (season_results_df[\"LAst\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LTO\"] = (season_results_df[\"LTO\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    # Losing defense\n",
    "    season_results_df[\"LDR\"] = (season_results_df[\"LDR\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LStl\"] = (season_results_df[\"LStl\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    season_results_df[\"LBlk\"] = (season_results_df[\"LBlk\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    # Losing offense & defense\n",
    "    season_results_df[\"LPF\"] = (season_results_df[\"LPF\"] / season_results_df[\"GameDuration\"]) * GAME_MINS\n",
    "    \n",
    "    season_results_df[\"WPointsMade\"] = (2 * (season_results_df[\"WFGM\"] - season_results_df[\"WFGM3\"])) + (3 * season_results_df[\"WFGM3\"]) + (1 * season_results_df[\"WFTM\"])\n",
    "    season_results_df[\"WPointsMissed\"] = ((2 * (season_results_df[\"WFGA\"] - season_results_df[\"WFGA3\"])) + (3 * season_results_df[\"WFGA3\"]) + (1 * season_results_df[\"WFTA\"])) - season_results_df[\"WPointsMade\"]\n",
    "    \n",
    "    season_results_df[\"LPointsMade\"] = (2 * (season_results_df[\"LFGM\"] - season_results_df[\"LFGM3\"])) + (3 * season_results_df[\"LFGM3\"]) + (1 * season_results_df[\"LFTM\"])\n",
    "    season_results_df[\"LPointsMissed\"] = ((2 * (season_results_df[\"LFGA\"] - season_results_df[\"LFGA3\"])) + (3 * season_results_df[\"LFGA3\"]) + (1 * season_results_df[\"LFTA\"])) - season_results_df[\"LPointsMade\"]\n",
    "    \n",
    "    season_results_df[\"WOffEff\"] = season_results_df[\"WPointsMade\"] + season_results_df[\"WAst\"] + season_results_df[\"WOR\"]\n",
    "    season_results_df[\"WDefEff\"] = season_results_df[\"LPointsMissed\"] + season_results_df[\"LTO\"] + season_results_df[\"WDR\"] + season_results_df[\"WStl\"] + season_results_df[\"WBlk\"] + season_results_df[\"WPF\"]\n",
    "    \n",
    "    season_results_df[\"LOffEff\"] = season_results_df[\"LPointsMade\"] + season_results_df[\"LAst\"] + season_results_df[\"LOR\"]\n",
    "    season_results_df[\"LDefEff\"] = season_results_df[\"WPointsMissed\"] + season_results_df[\"WTO\"] + season_results_df[\"LDR\"] + season_results_df[\"LStl\"] + season_results_df[\"LBlk\"] + season_results_df[\"LPF\"]\n",
    "    \n",
    "    w_eff_df = season_results_df[[\"WTeamID\", \"Season\", \"DayNum\", \"WOffEff\", \"WDefEff\"]]\n",
    "    w_eff_df = w_eff_df.rename(columns={\"WTeamID\": \"TeamID\", \"WOffEff\": \"OffEff\", \"WDefEff\": \"DefEff\"})\n",
    "    \n",
    "    l_eff_df = season_results_df[[\"LTeamID\", \"Season\", \"DayNum\", \"LOffEff\", \"LDefEff\"]]\n",
    "    l_eff_df = l_eff_df.rename(columns={\"LTeamID\": \"TeamID\", \"LOffEff\": \"OffEff\", \"LDefEff\": \"DefEff\"})\n",
    "    \n",
    "    eff_df = pd.concat([w_eff_df, l_eff_df]).sort_values(by=[\"Season\", \"DayNum\"]).reset_index(drop=True)\n",
    "    \n",
    "    eff_df.drop([\"DayNum\"], axis=1, inplace=True)\n",
    "    \n",
    "    eff_df = eff_df.groupby(by=[\"Season\", \"TeamID\"]).agg(\"mean\").reset_index()\n",
    "    \n",
    "    return eff_df\n",
    "    \n",
    "print(get_efficiency(m_regular_season_detailed_results_df))\n",
    "\n",
    "def get_rankings(rankings_df):\n",
    "    rankings_df = rankings_df.copy()\n",
    "    \n",
    "    rankings_df = rankings_df[rankings_df[\"RankingDayNum\"] == 133].reset_index(drop=True)\n",
    "    \n",
    "    mean_median_rankings_df = rankings_df.groupby([\"Season\", \"TeamID\"])[[\"OrdinalRank\"]].agg([(\"MeanOrdinalRank\", \"mean\"), (\"MedianOrdinalRank\", \"median\")])\n",
    "    mean_median_rankings_df.columns = mean_median_rankings_df.columns.droplevel(0)\n",
    "    mean_median_rankings_df = mean_median_rankings_df.reset_index()\n",
    "    \n",
    "    massey_rankings_df = rankings_df[rankings_df[\"SystemName\"] == \"MAS\"].reset_index(drop=True)\n",
    "    massey_rankings_df = massey_rankings_df.rename(columns={\"OrdinalRank\": \"MasseyOrdinalRank\"})\n",
    "    massey_rankings_df = massey_rankings_df[[\"Season\", \"TeamID\", \"MasseyOrdinalRank\"]].reset_index(drop=True)\n",
    "    \n",
    "    rankings_df = pd.merge(mean_median_rankings_df, massey_rankings_df, on=[\"Season\", \"TeamID\"], how=\"left\")\n",
    "    \n",
    "    return rankings_df\n",
    "    \n",
    "print(get_rankings(m_massey_ordinals_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rankings_df.sort_values(by=[\"Season\", \"MeanOrdinalRank\"], ignore_index=True).loc[25:50, :]\n",
    "\n",
    "\n",
    "def get_rankings_top_25(rankings_df, season_results_df):\n",
    "    rankings_df = rankings_df.copy()\n",
    "    season_results_df = season_results_df.copy()\n",
    "    \n",
    "#     rankings_df = rankings_df[rankings_df[\"RankingDayNum\"] == 128].reset_index(drop=True)\n",
    "    \n",
    "#     rankings_df = rankings_df.groupby([\"Season\", \"TeamID\"])[[\"OrdinalRank\"]].agg([(\"MeanOrdinalRank\", \"mean\"), (\"MedianOrdinalRank\", \"median\")])\n",
    "#     rankings_df.columns = rankings_df.columns.droplevel(0)\n",
    "#     rankings_df = rankings_df.reset_index()\n",
    "    \n",
    "#     rankings_df = pd.merge(rankings_df, season_results_df, left_on=[\"Season\", \"TeamID\"], right_on=[\"Season\", \"WTeamID\"])\n",
    "    \n",
    "    ### Average the ranking day's ordinal values\n",
    "    \n",
    "    rankings_wk_1_df = rankings_df[rankings_df[\"RankingDayNum\"] <= 7].reset_index(drop=True)\n",
    "    season_wk_1_results_df = season_results_df[season_results_df[\"DayNum\"] < 7].reset_index(drop=True)\n",
    "    \n",
    "    rankings_wk_1_df = rankings_wk_1_df.groupby([\"Season\", \"TeamID\"])[[\"OrdinalRank\"]].agg([(\"MeanOrdinalRank\", \"mean\"), (\"MedianOrdinalRank\", \"median\")])\n",
    "    rankings_wk_1_df.columns = rankings_wk_1_df.columns.droplevel(0)\n",
    "    rankings_wk_1_df = rankings_wk_1_df.reset_index()\n",
    "    \n",
    "    rankings_wk_1_df = pd.merge(rankings_wk_1_df, season_wk_1_results_df, left_on=[\"Season\", \"TeamID\"], right_on=[\"Season\", \"WTeamID\"], how=\"left\")\n",
    "    \n",
    "    \n",
    "    rankings_wk_2_df = rankings_df[(rankings_df[\"RankingDayNum\"] > 7) & (rankings_df[\"RankingDayNum\"] <= 14)].reset_index(drop=True)\n",
    "    season_wk_2_results_df = season_results_df[(season_results_df[\"DayNum\"] >= 7) & (season_results_df[\"DayNum\"] < 14)].reset_index(drop=True)\n",
    "\n",
    "    rankings_wk_2_df = rankings_wk_2_df.groupby([\"Season\", \"TeamID\"])[[\"OrdinalRank\"]].agg([(\"MeanOrdinalRank\", \"mean\"), (\"MedianOrdinalRank\", \"median\")])\n",
    "    rankings_wk_2_df.columns = rankings_wk_2_df.columns.droplevel(0)\n",
    "    rankings_wk_2_df = rankings_wk_2_df.reset_index()\n",
    "    \n",
    "    print(rankings_wk_2_df)\n",
    "    \n",
    "    rankings_df = pd.merge(rankings_wk_2_df, season_wk_2_results_df, left_on=[\"Season\", \"TeamID\"], right_on=[\"Season\", \"WTeamID\"], how=\"left\")\n",
    "    \n",
    "#     rankings_df = rankings_df[rankings_df[\"MeanOrdinalRank\"] < 26].reset_index(drop=True)\n",
    "\n",
    "#     rankings_df = pd.merge(rankings_df, season_results_df, left_on=[\"Season\", \"TeamID\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     rankings_df = rankings_df[rankings_df[\"RankingDayNum\"] == 133].reset_index(drop=True)\n",
    "    \n",
    "#     mean_median_rankings_df = rankings_df.groupby([\"Season\", \"TeamID\"])[[\"OrdinalRank\"]].agg([(\"MeanOrdinalRank\", \"mean\"), (\"MedianOrdinalRank\", \"median\")])\n",
    "#     mean_median_rankings_df.columns = mean_median_rankings_df.columns.droplevel(0)\n",
    "#     mean_median_rankings_df = mean_median_rankings_df.reset_index()\n",
    "    \n",
    "#     massey_rankings_df = rankings_df[rankings_df[\"SystemName\"] == \"MAS\"].reset_index(drop=True)\n",
    "#     massey_rankings_df = massey_rankings_df.rename(columns={\"OrdinalRank\": \"MasseyOrdinalRank\"})\n",
    "#     massey_rankings_df = massey_rankings_df[[\"Season\", \"TeamID\", \"MasseyOrdinalRank\"]].reset_index(drop=True)\n",
    "    \n",
    "#     rankings_df = pd.merge(mean_median_rankings_df, massey_rankings_df, on=[\"Season\", \"TeamID\"], how=\"left\")\n",
    "    \n",
    "    return rankings_df.sort_values(by=[\"Season\", \"MeanOrdinalRank\"]).reset_index(drop=True)\n",
    "\n",
    "get_rankings_top_25(m_massey_ordinals_df, m_regular_season_compact_results_df)\n",
    "# m_massey_ordinals_df\n",
    "\n",
    "# m_massey_ordinals_df.loc[:, \"RankingDayNum\"].value_counts().sort_index().index#[-20:]\n",
    "# m_massey_ordinals_df.loc[:, \"RankingDayNum\"].value_counts().sort_index()[0:-1]\n",
    "# len(m_massey_ordinals_df)\n",
    "# m_regular_season_compact_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ID  Season  TeamID_1  TeamID_2  Result\n",
      "0      2015_1103_1420    2015      1103      1420       1\n",
      "1      2015_1104_1406    2015      1104      1406       1\n",
      "2      2015_1112_1291    2015      1112      1291       1\n",
      "3      2015_1113_1152    2015      1113      1152       1\n",
      "4      2015_1119_1102    2015      1119      1102       1\n",
      "...               ...     ...       ...       ...     ...\n",
      "53967  2019_1222_1153    2019      1222      1153       0\n",
      "53968  2019_1426_1209    2019      1426      1209       0\n",
      "53969  2019_1276_1277    2019      1276      1277       0\n",
      "53970  2019_1382_1387    2019      1382      1387       0\n",
      "53971  2019_1217_1463    2019      1217      1463       0\n",
      "\n",
      "[53972 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def prep_season(season_results_df):\n",
    "    season_results_df = season_results_df.copy()\n",
    "    \n",
    "    seasons = season_results_df[\"Season\"]\n",
    "    season_min_gt = seasons > 2014\n",
    "    season_max_lt = seasons < 2020\n",
    "    all_teams_df = season_results_df[season_min_gt & season_max_lt].reset_index(drop=True)\n",
    "    \n",
    "    w_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    w_teams_df = w_teams_df.rename(columns={\"WTeamID\": \"TeamID_1\", \"LTeamID\": \"TeamID_2\"})\n",
    "    w_teams_df[\"Result\"] = 1\n",
    "    \n",
    "    l_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    l_teams_df = l_teams_df.rename(columns={\"WTeamID\": \"TeamID_2\", \"LTeamID\": \"TeamID_1\"})\n",
    "    l_teams_df[\"Result\"] = 0\n",
    "    \n",
    "    all_teams_df = pd.concat([w_teams_df, l_teams_df]).reset_index(drop=True)\n",
    "    \n",
    "    all_teams_df[\"ID\"] = all_teams_df[\"Season\"].apply(str) + \"_\" + all_teams_df[\"TeamID_1\"].apply(str) + \"_\" + all_teams_df[\"TeamID_2\"].apply(str)\n",
    "    \n",
    "    all_teams_df = all_teams_df[[\"ID\", \"Season\", \"TeamID_1\", \"TeamID_2\", \"Result\"]]\n",
    "    \n",
    "    return all_teams_df\n",
    "    \n",
    "print(prep_season(m_regular_season_compact_results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ID  Season  TeamID_1  TeamID_2  Result\n",
      "0       1985_1228_1328    1985      1228      1328       1\n",
      "1       1985_1106_1354    1985      1106      1354       1\n",
      "2       1985_1112_1223    1985      1112      1223       1\n",
      "3       1985_1165_1432    1985      1165      1432       1\n",
      "4       1985_1192_1447    1985      1192      1447       1\n",
      "...                ...     ...       ...       ...     ...\n",
      "341471  2021_1433_1382    2021      1433      1382       0\n",
      "341472  2021_1259_1159    2021      1259      1159       0\n",
      "341473  2021_1261_1104    2021      1261      1104       0\n",
      "341474  2021_1153_1222    2021      1153      1222       0\n",
      "341475  2021_1326_1228    2021      1326      1228       0\n",
      "\n",
      "[341476 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def prep_season(season_results_df):\n",
    "    season_results_df = season_results_df.copy()\n",
    "    \n",
    "#     seasons = season_results_df[\"Season\"]\n",
    "#     season_min_gt = seasons > 2014\n",
    "#     season_max_lt = seasons < 2020\n",
    "    all_teams_df = season_results_df#[season_min_gt & season_max_lt].reset_index(drop=True)\n",
    "    \n",
    "    w_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    w_teams_df = w_teams_df.rename(columns={\"WTeamID\": \"TeamID_1\", \"LTeamID\": \"TeamID_2\"})\n",
    "    w_teams_df[\"Result\"] = 1\n",
    "    \n",
    "    l_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    l_teams_df = l_teams_df.rename(columns={\"WTeamID\": \"TeamID_2\", \"LTeamID\": \"TeamID_1\"})\n",
    "    l_teams_df[\"Result\"] = 0\n",
    "    \n",
    "    all_teams_df = pd.concat([w_teams_df, l_teams_df]).reset_index(drop=True)\n",
    "    \n",
    "    all_teams_df[\"ID\"] = all_teams_df[\"Season\"].apply(str) + \"_\" + all_teams_df[\"TeamID_1\"].apply(str) + \"_\" + all_teams_df[\"TeamID_2\"].apply(str)\n",
    "    \n",
    "    all_teams_df = all_teams_df[[\"ID\", \"Season\", \"TeamID_1\", \"TeamID_2\", \"Result\"]]\n",
    "    \n",
    "    return all_teams_df\n",
    "    \n",
    "print(prep_season(m_regular_season_compact_results_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_predictions(sample_output_df, ncaa_tourney_results_df):\n",
    "    features_df = sample_output_df.copy()\n",
    "    features_df[\"Season\"] = features_df[\"ID\"].apply(lambda row: int(row[:4]))\n",
    "    features_df[\"TeamID_1\"] = features_df[\"ID\"].apply(lambda row: int(row[5:9]))\n",
    "    features_df[\"TeamID_2\"] = features_df[\"ID\"].apply(lambda row: int(row[10:14]))\n",
    "    features_df.drop([\"Pred\"], axis=1, inplace=True)\n",
    "    \n",
    "    ncaa_tourney_results_df = ncaa_tourney_results_df.copy()\n",
    "    seasons = ncaa_tourney_results_df[\"Season\"]\n",
    "    season_min_gt = seasons > 2014\n",
    "    season_max_lt = seasons < 2020\n",
    "    all_teams_df = ncaa_tourney_results_df[season_min_gt & season_max_lt].reset_index(drop=True)\n",
    "    \n",
    "    w_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    w_teams_df = w_teams_df.rename(columns={\"WTeamID\": \"TeamID_1\", \"LTeamID\": \"TeamID_2\"})\n",
    "    w_teams_df[\"Result\"] = 1\n",
    "    \n",
    "    l_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    l_teams_df = l_teams_df.rename(columns={\"WTeamID\": \"TeamID_2\", \"LTeamID\": \"TeamID_1\"})\n",
    "    l_teams_df[\"Result\"] = 0\n",
    "    \n",
    "    all_teams_df = pd.concat([w_teams_df, l_teams_df]).reset_index(drop=True)\n",
    "    \n",
    "    features_df = features_df.merge(all_teams_df, on=[\"Season\", \"TeamID_1\", \"TeamID_2\"], how=\"left\")\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_features(features_df, ppg_df, eff_df, rankings_df):\n",
    "    features_df = features_df.copy()\n",
    "    ppg_df = ppg_df.copy()\n",
    "    eff_df = eff_df.copy()\n",
    "    rankings_df = rankings_df.copy()\n",
    "    \n",
    "    w_ppg_df = ppg_df.rename(columns={\"PPG\": \"PPG_1\", \"WPerc\": \"WPerc_1\"})\n",
    "    l_ppg_df = ppg_df.rename(columns={\"PPG\": \"PPG_2\", \"WPerc\": \"WPerc_2\"})\n",
    "    \n",
    "    features_df = pd.merge(features_df, w_ppg_df, left_on=[\"Season\", \"TeamID_1\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\", \"Games\"], axis=1, inplace=True)\n",
    "    features_df = pd.merge(features_df, l_ppg_df, left_on=[\"Season\", \"TeamID_2\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\", \"Games\"], axis=1, inplace=True)\n",
    "    \n",
    "    w_eff_df = eff_df.rename(columns={\"OffEff\": \"OffEff_1\", \"DefEff\": \"DefEff_1\"})\n",
    "    l_eff_df = eff_df.rename(columns={\"OffEff\": \"OffEff_2\", \"DefEff\": \"DefEff_2\"})\n",
    "    \n",
    "    features_df = pd.merge(features_df, w_eff_df, left_on=[\"Season\", \"TeamID_1\"], right_on=[\"Season\", \"TeamID\"], how=\"left\")#.reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    features_df = pd.merge(features_df, l_eff_df, left_on=[\"Season\", \"TeamID_2\"], right_on=[\"Season\", \"TeamID\"], how=\"left\")#.reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    \n",
    "    features_df[\"PPGDiff\"] = features_df[\"PPG_1\"] - features_df[\"PPG_2\"]\n",
    "    features_df[\"WPercDiff\"] = features_df[\"WPerc_1\"] - features_df[\"WPerc_2\"]\n",
    "    features_df[\"OffEffDiff\"] = features_df[\"OffEff_1\"] - features_df[\"OffEff_2\"]\n",
    "    features_df[\"DefEffDiff\"] = features_df[\"DefEff_1\"] - features_df[\"DefEff_2\"]\n",
    "    features_df.drop([\"PPG_1\", \"PPG_2\", \"WPerc_1\", \"WPerc_2\", \"OffEff_1\", \"OffEff_2\", \"DefEff_1\", \"DefEff_2\"], axis=1, inplace=True)\n",
    "    \n",
    "    w_rankings_df = rankings_df.rename(columns={\"MeanOrdinalRank\": \"MeanOrdinalRank_1\", \"MedianOrdinalRank\": \"MedianOrdinalRank_1\", \"MasseyOrdinalRank\": \"MasseyOrdinalRank_1\"})\n",
    "    l_rankings_df = rankings_df.rename(columns={\"MeanOrdinalRank\": \"MeanOrdinalRank_2\", \"MedianOrdinalRank\": \"MedianOrdinalRank_2\", \"MasseyOrdinalRank\": \"MasseyOrdinalRank_2\"})\n",
    "    \n",
    "    features_df = pd.merge(features_df, w_rankings_df, left_on=[\"Season\", \"TeamID_1\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    features_df = pd.merge(features_df, l_rankings_df, left_on=[\"Season\", \"TeamID_2\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    \n",
    "    features_df[\"MeanOrdinalRankDiff\"] = features_df[\"MeanOrdinalRank_1\"] - features_df[\"MeanOrdinalRank_2\"]\n",
    "    features_df[\"MedianOrdinalRankDiff\"] = features_df[\"MedianOrdinalRank_1\"] - features_df[\"MedianOrdinalRank_2\"]\n",
    "    features_df[\"MasseyOrdinalRankDiff\"] = features_df[\"MasseyOrdinalRank_1\"] - features_df[\"MasseyOrdinalRank_2\"]\n",
    "    features_df.drop([\"MeanOrdinalRank_1\", \"MeanOrdinalRank_2\", \"MedianOrdinalRank_1\", \"MedianOrdinalRank_2\", \"MasseyOrdinalRank_1\", \"MasseyOrdinalRank_2\"], axis=1, inplace=True)\n",
    "    \n",
    "    bpi_df = get_bpi(m_ncaa_bpi_21_df)\n",
    "    \n",
    "    w_bpi_df = bpi_df.rename(columns={\"BPI RK\": \"BPI RK_1\"})\n",
    "    l_bpi_df = bpi_df.rename(columns={\"BPI RK\": \"BPI RK_2\"})\n",
    "    \n",
    "    features_df = pd.merge(features_df, w_bpi_df, left_on=[\"Season\", \"TeamID_1\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    features_df = pd.merge(features_df, l_bpi_df, left_on=[\"Season\", \"TeamID_2\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    \n",
    "    sos_df = get_sos(m_ncaa_bpi_21_df)\n",
    "    \n",
    "    w_sos_df = sos_df.rename(columns={\"SOS RK\": \"SOS RK_1\"})\n",
    "    l_sos_df = sos_df.rename(columns={\"SOS RK\": \"SOS RK_2\"})\n",
    "    \n",
    "    features_df = pd.merge(features_df, w_sos_df, left_on=[\"Season\", \"TeamID_1\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    features_df = pd.merge(features_df, l_sos_df, left_on=[\"Season\", \"TeamID_2\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    \n",
    "    sor_df = get_sor(m_ncaa_bpi_21_df)\n",
    "    \n",
    "    w_sor_df = sor_df.rename(columns={\"SOR RK\": \"SOR RK_1\"})\n",
    "    l_sor_df = sor_df.rename(columns={\"SOR RK\": \"SOR RK_2\"})\n",
    "    \n",
    "    features_df = pd.merge(features_df, w_sor_df, left_on=[\"Season\", \"TeamID_1\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    features_df = pd.merge(features_df, l_sor_df, left_on=[\"Season\", \"TeamID_2\"], right_on=[\"Season\", \"TeamID\"], how=\"left\").reset_index(drop=True)\n",
    "    features_df.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "    \n",
    "    features_df[\"BPI RKDiff\"] = features_df[\"BPI RK_1\"] - features_df[\"BPI RK_2\"]\n",
    "    features_df[\"SOS RKDiff\"] = features_df[\"SOS RK_1\"] - features_df[\"SOS RK_2\"]\n",
    "    features_df[\"SOR RKDiff\"] = features_df[\"SOR RK_1\"] - features_df[\"SOR RK_2\"]\n",
    "    \n",
    "    features_df.drop([\"BPI RK_1\", \"BPI RK_2\", \"SOS RK_1\", \"SOS RK_2\", \"SOR RK_1\", \"SOR RK_2\"], axis=1, inplace=True)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = prepare_predictions(hist_sample_subm_df, m_ncaa_tourney_compact_results_df)\n",
    "ppg_df = get_ppg(m_regular_season_compact_results_df)\n",
    "# ppg_vs_team_df = get_ppg_vs_team(m_regular_season_compact_results_df)\n",
    "# ppg_vs_team_all_time_df = get_ppg_vs_team_all_time(m_regular_season_compact_results_df)\n",
    "eff_df = get_efficiency(m_regular_season_detailed_results_df)\n",
    "rankings_df = get_rankings(m_massey_ordinals_df)\n",
    "tourney_df = merge_features(features_df, ppg_df, eff_df, rankings_df)\n",
    "\n",
    "train_features_df = prep_season(m_regular_season_compact_results_df)\n",
    "reg_season_df = merge_features(train_features_df, ppg_df, eff_df, rankings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID_1</th>\n",
       "      <th>TeamID_2</th>\n",
       "      <th>Result</th>\n",
       "      <th>PPGDiff</th>\n",
       "      <th>WPercDiff</th>\n",
       "      <th>OffEffDiff</th>\n",
       "      <th>DefEffDiff</th>\n",
       "      <th>MeanOrdinalRankDiff</th>\n",
       "      <th>MedianOrdinalRankDiff</th>\n",
       "      <th>MasseyOrdinalRankDiff</th>\n",
       "      <th>BPI RK_1</th>\n",
       "      <th>BPI RK_2</th>\n",
       "      <th>SOS RK_1</th>\n",
       "      <th>SOS RK_2</th>\n",
       "      <th>SOR RK_1</th>\n",
       "      <th>SOR RK_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015_1107_1112</td>\n",
       "      <td>2015</td>\n",
       "      <td>1107</td>\n",
       "      <td>1112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.978962</td>\n",
       "      <td>-0.161765</td>\n",
       "      <td>-15.602737</td>\n",
       "      <td>-13.001021</td>\n",
       "      <td>114.669633</td>\n",
       "      <td>118.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015_1107_1116</td>\n",
       "      <td>2015</td>\n",
       "      <td>1107</td>\n",
       "      <td>1116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.266544</td>\n",
       "      <td>-0.014706</td>\n",
       "      <td>-20.880515</td>\n",
       "      <td>-15.938930</td>\n",
       "      <td>96.572859</td>\n",
       "      <td>100.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015_1107_1124</td>\n",
       "      <td>2015</td>\n",
       "      <td>1107</td>\n",
       "      <td>1124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.444444</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>-11.822917</td>\n",
       "      <td>-12.343750</td>\n",
       "      <td>104.701891</td>\n",
       "      <td>108.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015_1107_1125</td>\n",
       "      <td>2015</td>\n",
       "      <td>1107</td>\n",
       "      <td>1125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.527666</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>-12.703517</td>\n",
       "      <td>-8.132056</td>\n",
       "      <td>-10.844828</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015_1107_1129</td>\n",
       "      <td>2015</td>\n",
       "      <td>1107</td>\n",
       "      <td>1129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.360641</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>-2.926456</td>\n",
       "      <td>-2.106250</td>\n",
       "      <td>72.179310</td>\n",
       "      <td>74.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11385</th>\n",
       "      <td>2019_1449_1459</td>\n",
       "      <td>2019</td>\n",
       "      <td>1449</td>\n",
       "      <td>1459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.376471</td>\n",
       "      <td>-0.101961</td>\n",
       "      <td>-15.229412</td>\n",
       "      <td>6.939216</td>\n",
       "      <td>17.703591</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11386</th>\n",
       "      <td>2019_1449_1463</td>\n",
       "      <td>2019</td>\n",
       "      <td>1449</td>\n",
       "      <td>1463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.069328</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>-15.600840</td>\n",
       "      <td>-10.615546</td>\n",
       "      <td>-36.156250</td>\n",
       "      <td>-34.5</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11387</th>\n",
       "      <td>2019_1458_1459</td>\n",
       "      <td>2019</td>\n",
       "      <td>1458</td>\n",
       "      <td>1459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.139394</td>\n",
       "      <td>-0.169697</td>\n",
       "      <td>-16.230303</td>\n",
       "      <td>5.339394</td>\n",
       "      <td>-4.492537</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11388</th>\n",
       "      <td>2019_1458_1463</td>\n",
       "      <td>2019</td>\n",
       "      <td>1458</td>\n",
       "      <td>1463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.832251</td>\n",
       "      <td>-0.053030</td>\n",
       "      <td>-16.601732</td>\n",
       "      <td>-12.215368</td>\n",
       "      <td>-58.352379</td>\n",
       "      <td>-58.5</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>2019_1459_1463</td>\n",
       "      <td>2019</td>\n",
       "      <td>1459</td>\n",
       "      <td>1463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307143</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>-0.371429</td>\n",
       "      <td>-17.554762</td>\n",
       "      <td>-53.859841</td>\n",
       "      <td>-53.5</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11390 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  Season  TeamID_1  TeamID_2  Result    PPGDiff  \\\n",
       "0      2015_1107_1112    2015      1107      1112     NaN -10.978962   \n",
       "1      2015_1107_1116    2015      1107      1116     NaN -12.266544   \n",
       "2      2015_1107_1124    2015      1107      1124     NaN  -3.444444   \n",
       "3      2015_1107_1125    2015      1107      1125     NaN  -8.527666   \n",
       "4      2015_1107_1129    2015      1107      1129     NaN  -3.360641   \n",
       "...               ...     ...       ...       ...     ...        ...   \n",
       "11385  2019_1449_1459    2019      1449      1459     NaN -11.376471   \n",
       "11386  2019_1449_1463    2019      1449      1463     NaN -11.069328   \n",
       "11387  2019_1458_1459    2019      1458      1459     NaN -12.139394   \n",
       "11388  2019_1458_1463    2019      1458      1463     NaN -11.832251   \n",
       "11389  2019_1459_1463    2019      1459      1463     NaN   0.307143   \n",
       "\n",
       "       WPercDiff  OffEffDiff  DefEffDiff  MeanOrdinalRankDiff  \\\n",
       "0      -0.161765  -15.602737  -13.001021           114.669633   \n",
       "1      -0.014706  -20.880515  -15.938930            96.572859   \n",
       "2       0.031250  -11.822917  -12.343750           104.701891   \n",
       "3       0.072581  -12.703517   -8.132056           -10.844828   \n",
       "4       0.008065   -2.926456   -2.106250            72.179310   \n",
       "...          ...         ...         ...                  ...   \n",
       "11385  -0.101961  -15.229412    6.939216            17.703591   \n",
       "11386   0.014706  -15.600840  -10.615546           -36.156250   \n",
       "11387  -0.169697  -16.230303    5.339394            -4.492537   \n",
       "11388  -0.053030  -16.601732  -12.215368           -58.352379   \n",
       "11389   0.116667   -0.371429  -17.554762           -53.859841   \n",
       "\n",
       "       MedianOrdinalRankDiff  MasseyOrdinalRankDiff  BPI RK_1  BPI RK_2  \\\n",
       "0                      118.0                   90.0       NaN       NaN   \n",
       "1                      100.0                   81.0       NaN       NaN   \n",
       "2                      108.0                   79.0       NaN       NaN   \n",
       "3                      -12.0                  -11.0       NaN       NaN   \n",
       "4                       74.5                   42.0       NaN       NaN   \n",
       "...                      ...                    ...       ...       ...   \n",
       "11385                   19.0                   30.0       NaN       NaN   \n",
       "11386                  -34.5                  -32.0       NaN       NaN   \n",
       "11387                   -5.0                    7.0       NaN       NaN   \n",
       "11388                  -58.5                  -55.0       NaN       NaN   \n",
       "11389                  -53.5                  -62.0       NaN       NaN   \n",
       "\n",
       "       SOS RK_1  SOS RK_2  SOR RK_1  SOR RK_2  \n",
       "0           NaN       NaN       NaN       NaN  \n",
       "1           NaN       NaN       NaN       NaN  \n",
       "2           NaN       NaN       NaN       NaN  \n",
       "3           NaN       NaN       NaN       NaN  \n",
       "4           NaN       NaN       NaN       NaN  \n",
       "...         ...       ...       ...       ...  \n",
       "11385       NaN       NaN       NaN       NaN  \n",
       "11386       NaN       NaN       NaN       NaN  \n",
       "11387       NaN       NaN       NaN       NaN  \n",
       "11388       NaN       NaN       NaN       NaN  \n",
       "11389       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[11390 rows x 18 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_season_df[reg_season_df[\"BPI RK_1\"].isna()]\n",
    "tourney_df[tourney_df[\"BPI RK_1\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = reg_season_df[[\n",
    "    \"PPGDiff\", \"WPercDiff\", \"OffEffDiff\", \"DefEffDiff\",\n",
    "    \"MeanOrdinalRankDiff\",\"MedianOrdinalRankDiff\", \"MasseyOrdinalRankDiff\"\n",
    "]]\n",
    "y_train = reg_season_df[[\"Result\"]]\n",
    "\n",
    "tourney_actuals_df = tourney_df.copy().dropna()\n",
    "x_test = tourney_actuals_df[[\n",
    "    \"PPGDiff\", \"WPercDiff\", \"OffEffDiff\", \"DefEffDiff\",\n",
    "    \"MeanOrdinalRankDiff\",\"MedianOrdinalRankDiff\", \"MasseyOrdinalRankDiff\"\n",
    "]]\n",
    "y_test = tourney_actuals_df[[\"Result\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, n_jobs=-1, verbose=1)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "log_reg = LogisticRegression(penalty=\"l2\", random_state=None, max_iter=1000, verbose=1, n_jobs=-1)\n",
    "\n",
    "log_reg.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 7)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-8010daf07994>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\brady\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1466\u001b[0m                                                 self.solver == 'liblinear')))\n\u001b[0;32m   1467\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0movr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1468\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1469\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1470\u001b[0m             \u001b[0mdecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\brady\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \"\"\"\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[0mexpit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\brady\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\brady\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\brady\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001b[0m\u001b[0;32m    651\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 7)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))\n",
    "\n",
    "# y_pred = log_reg.predict_proba(\n",
    "#     tourney_df[[\n",
    "#         \"PPGDiff\", \"WPercDiff\", \"OffEffDiff\", \"DefEffDiff\",\n",
    "#         \"MeanOrdinalRankDiff\",\"MedianOrdinalRankDiff\", \"MasseyOrdinalRankDiff\"\n",
    "#     ]]\n",
    "# )\n",
    "# y_pred = y_pred[:, 1]\n",
    "\n",
    "# stage_1_submission_df = tourney_df[[\"ID\"]].copy()\n",
    "# stage_1_submission_df[\"Pred\"] = y_pred\n",
    "# stage_1_submission_df.to_csv(\"brady_lange_m_submission_stage_01_log_reg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(loss=\"log\", verbose=1, n_jobs=-1)\n",
    "\n",
    "sgd_clf.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd_clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(\n",
    "    loss=\"deviance\",\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=500,\n",
    "    subsample=0.5,\n",
    "    criterion=\"friedman_mse\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gb_clf.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb_clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))\n",
    "\n",
    "y_pred = knn_clf.predict_proba(\n",
    "    tourney_df[[\n",
    "        \"PPGDiff\", \"WPercDiff\", \"OffEffDiff\", \"DefEffDiff\",\n",
    "        \"MeanOrdinalRankDiff\",\"MedianOrdinalRankDiff\", \"MasseyOrdinalRankDiff\"\n",
    "    ]]\n",
    ")\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "stage_1_submission_df = tourney_df[[\"ID\"]].copy()\n",
    "stage_1_submission_df[\"Pred\"] = y_pred\n",
    "stage_1_submission_df.to_csv(\"brady_lange_m_submission_stage_01_gb_clf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "dt_clf.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt_clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "rf_clf.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Importance\": rf_clf.feature_importances_,\n",
    "        \"Features\": [\n",
    "            \"PPGDiff\", \"WPercDiff\", \"OffEffDiff\", \"DefEffDiff\",\n",
    "            \"MeanOrdinalRankDiff\",\"MedianOrdinalRankDiff\", \"MasseyOrdinalRankDiff\"\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classification - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_clf = SVC(probability=True)\n",
    "\n",
    "svc_clf.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classification - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=1500, n_jobs=-1)\n",
    "\n",
    "knn_clf.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))\n",
    "\n",
    "y_pred = knn_clf.predict_proba(\n",
    "    tourney_df[[\n",
    "        \"PPGDiff\", \"WPercDiff\", \"OffEffDiff\", \"DefEffDiff\",\n",
    "        \"MeanOrdinalRankDiff\",\"MedianOrdinalRankDiff\", \"MasseyOrdinalRankDiff\"\n",
    "    ]]\n",
    ")\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "stage_1_submission_df = tourney_df[[\"ID\"]].copy()\n",
    "stage_1_submission_df[\"Pred\"] = y_pred\n",
    "stage_1_submission_df.to_csv(\"brady_lange_m_submission_stage_01_knn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_clf = MLPClassifier(activation=\"logistic\")\n",
    "\n",
    "mlp_clf.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp_clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_boost_clf = AdaBoostClassifier()\n",
    "\n",
    "ada_boost_clf.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ada_boost_clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gausian Naive Bayes - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_clf = GaussianNB()\n",
    "\n",
    "gnb_clf.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gausian Naive Bayes - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb_clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda_clf = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "qda_clf.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis - Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = qda_clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "print(log_loss(y_test, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "y_pred_rand = [random() for item in range(0, 335)]\n",
    "\n",
    "print(log_loss(y_test, y_pred_rand, eps=1e-15, normalize=True, sample_weight=None, labels=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2021 March Madness All Possible Matchups Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.ncaa.com/news/basketball-men/article/2021-03-12/2021-bracketology-march-madness-predictions-andy-katz\n",
    "\n",
    "# mock_mm_2021_matchups = [\n",
    "#     \"Gonzaga\", \"Prairie View/North Carolina A&T\",\n",
    "#     \"Michigan\", \"Bryant/Hartford\",\n",
    "#     \"Baylor\", \"Drexel\",\n",
    "#     \"Illinois\", \"Nicholls State\",\n",
    "#     \"San Diego State\", \"Loyola Chicago\",\n",
    "#     \"BYU\", \"North Carolina\",\n",
    "#     \"Missouri\", \"Rutgers\",\n",
    "#     \"UCLA\", \"Florida\",\n",
    "#     \"Oklahoma\", \"Colorado State/Syracuse\",\n",
    "#     \"Virginia\", \"Wichita State\",\n",
    "#     \"USC\", \"Toledo\",\n",
    "#     \"Texas Tech\", \"Western Kentucky\",\n",
    "#     \"Florida State\", \"Winthrop\",\n",
    "#     \"Texas\", \"Morehead State\",\n",
    "#     \"Oklahoma State\", \"UC Santa Barbara\",\n",
    "#     \"Purdue\", \"Liberty\",\n",
    "#     \"Creighton\", \"St. Bonaventure\",\n",
    "#     \"Oregon\", \"Drake/Boise State\",\n",
    "#     \"Clemson\", \"VCU\",\n",
    "#     \"Colorado\", \"Louisville\",\n",
    "#     \"Tennessee\", \"Georgia Tech\",\n",
    "#     \"Virginia Tech\", \"Michigan State\",\n",
    "#     \"UConn\", \"Maryland\",\n",
    "#     \"Wisconsin\", \"LSU\",\n",
    "#     \"Ohio State\", \"Grand Canyon\",\n",
    "#     \"Alabama\", \"Appalachian State\",\n",
    "#     \"Iowa\", \"Siena\",\n",
    "#     \"Houston\", \"Cleveland State\"\n",
    "# ]\n",
    "\n",
    "mock_mm_2021_matchups = [\n",
    "    \"Gonzaga\", \"Prairie View\",\n",
    "    \"Michigan\", \"Bryant\",\n",
    "    \"Baylor\", \"Drexel\",\n",
    "    \"Illinois\", \"Nicholls State\",\n",
    "    \"San Diego State\", \"Loyola Chicago\",\n",
    "    \"BYU\", \"North Carolina\",\n",
    "    \"Missouri\", \"Rutgers\",\n",
    "    \"UCLA\", \"Florida\",\n",
    "    \"Oklahoma\", \"Colorado State\",\n",
    "    \"Virginia\", \"Wichita State\",\n",
    "    \"USC\", \"Toledo\",\n",
    "    \"Texas Tech\", \"Western Kentucky\",\n",
    "    \"Florida State\", \"Winthrop\",\n",
    "    \"Texas\", \"Morehead State\",\n",
    "    \"Oklahoma State\", \"UC Santa Barbara\",\n",
    "    \"Purdue\", \"Liberty\",\n",
    "    \"Creighton\", \"St. Bonaventure\",\n",
    "    \"Oregon\", \"Drake\",\n",
    "    \"Clemson\", \"VCU\",\n",
    "    \"Colorado\", \"Louisville\",\n",
    "    \"Tennessee\", \"Georgia Tech\",\n",
    "    \"Virginia Tech\", \"Michigan State\",\n",
    "    \"UConn\", \"Maryland\",\n",
    "    \"Wisconsin\", \"LSU\",\n",
    "    \"Ohio State\", \"Grand Canyon\",\n",
    "    \"Alabama\", \"Appalachian State\",\n",
    "    \"Iowa\", \"Siena\",\n",
    "    \"Houston\", \"Cleveland State\"\n",
    "]\n",
    "\n",
    "# mm_2021_matchups = [\n",
    "#     \"Gonzaga\", \"Norfolk St/Appalachian State\",\n",
    "#     \"Oklahoma\", \"Missouri\",\n",
    "#     \"Virginia\", \"Ohio\",\n",
    "#     \"Creighton\", \"UC Santa Barbara\",\n",
    "#     \"Kansas\", \"Eastern Washington\",\n",
    "#     \"USC\", \"Wichita State/Drake\",\n",
    "#     \"Oregon\", \"VCU\",\n",
    "#     \"Iowa\", \"Grand Canyon\",\n",
    "#     \"Baylor\", \"Hartford\",\n",
    "#     \"North Carolina\", \"Wisconsin\",\n",
    "#     \"Purdue\", \"North Texas\",\n",
    "#     \"Villanova\", \"Winthrop\",\n",
    "#     \"Arkansas\", \"Colgate\",\n",
    "#     \"Texas Tech\", \"Utah State\",\n",
    "#     \"Florida\", \"Virginia Tech\",\n",
    "#     \"Ohio State\", \"Oral Roberts\",\n",
    "#     \"Illinois\", \"Drexel\",\n",
    "#     \"Loyola-Chicago\", \"Georgia Tech\",\n",
    "#     \"Oklahoma State\", \"Liberty\",\n",
    "#     \"Tennessee\", \"Oregon State\",\n",
    "#     \"West Virginia\", \"Morehead State\",\n",
    "#     \"San Diego State\", \"Syracuse\",\n",
    "#     \"Clemson\", \"Rutgers\",\n",
    "#     \"Houston\", \"Cleveland State\",\n",
    "#     \"Michigan\", \"Mount St. Mary's/Texas Southern\",\n",
    "#     \"LSU\", \"St. Bonaventure\",\n",
    "#     \"Florida State\", \"UNC Greensboro\",\n",
    "#     \"Colorado\", \"Georgetown\",\n",
    "#     \"Texas\", \"Abilene Christian\",\n",
    "#     \"BYU\", \"Michigan State/UCLA\",\n",
    "#     \"UConn\", \"Maryland\",\n",
    "#     \"Alabama\", \"Iona\"\n",
    "# ]\n",
    "\n",
    "mm_2021_matchups = [\n",
    "    \"Gonzaga\", \"Appalachian State\",\n",
    "    \"Oklahoma\", \"Missouri\",\n",
    "    \"Virginia\", \"Ohio\",\n",
    "    \"Creighton\", \"UC Santa Barbara\",\n",
    "    \"Kansas\", \"Eastern Washington\",\n",
    "    \"USC\", \"Drake\",\n",
    "    \"Oregon\", \"VCU\",\n",
    "    \"Iowa\", \"Grand Canyon\",\n",
    "    \"Baylor\", \"Hartford\",\n",
    "    \"North Carolina\", \"Wisconsin\",\n",
    "    \"Purdue\", \"North Texas\",\n",
    "    \"Villanova\", \"Winthrop\",\n",
    "    \"Arkansas\", \"Colgate\",\n",
    "    \"Texas Tech\", \"Utah State\",\n",
    "    \"Florida\", \"Virginia Tech\",\n",
    "    \"Ohio State\", \"Oral Roberts\",\n",
    "    \"Illinois\", \"Drexel\",\n",
    "    \"Loyola-Chicago\", \"Georgia Tech\",\n",
    "    \"Oklahoma State\", \"Liberty\",\n",
    "    \"Tennessee\", \"Oregon State\",\n",
    "    \"West Virginia\", \"Morehead State\",\n",
    "    \"San Diego State\", \"Syracuse\",\n",
    "    \"Clemson\", \"Rutgers\",\n",
    "    \"Houston\", \"Cleveland State\",\n",
    "    \"Michigan\", \"Texas Southern\",\n",
    "    \"LSU\", \"St. Bonaventure\",\n",
    "    \"Florida State\", \"UNC Greensboro\",\n",
    "    \"Colorado\", \"Georgetown\",\n",
    "    \"Texas\", \"Abilene Christian\",\n",
    "    \"BYU\", \"Michigan State\",\n",
    "    \"UConn\", \"Maryland\",\n",
    "    \"Alabama\", \"Iona\"\n",
    "]\n",
    "\n",
    "mock_mm_2021_matchups = [team.lower() for team in mock_mm_2021_matchups]\n",
    "mm_2021_matchups = [team.lower() for team in mm_2021_matchups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mock_mm_2021_matchups))\n",
    "print(len(m_teams_df[m_teams_df[\"TeamName\"].isin(mock_mm_2021_matchups)]))\n",
    "\n",
    "mock_matchups_df = pd.DataFrame({\"TeamName\": mock_mm_2021_matchups})\n",
    "mock_matchups_df = pd.merge(mock_matchups_df, m_team_spellings_df, left_on=\"TeamName\", right_on=\"TeamNameSpelling\", how=\"left\").reset_index(drop=True)\n",
    "mock_matchups_df.drop([\"TeamNameSpelling\"], axis=1, inplace=True)\n",
    "mock_matchups_df\n",
    "\n",
    "print(len(mm_2021_matchups))\n",
    "print(len(m_teams_df[m_teams_df[\"TeamName\"].isin(mm_2021_matchups)]))\n",
    "\n",
    "matchups_df = pd.DataFrame({\"TeamName\": mm_2021_matchups})\n",
    "matchups_df = pd.merge(matchups_df, m_team_spellings_df, left_on=\"TeamName\", right_on=\"TeamNameSpelling\", how=\"left\").reset_index(drop=True)\n",
    "matchups_df.drop([\"TeamNameSpelling\"], axis=1, inplace=True)\n",
    "matchups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep2021(matchups_df, ppg_df, eff_df, rankings_df):\n",
    "    matchups_df = pd.DataFrame(matchups_df.values.reshape(-1, 4), columns=[\"TeamName_1\", \"TeamID_1\", \"TeamName_2\", \"TeamID_2\"])\n",
    "    \n",
    "    matchups_df.loc[\n",
    "        matchups_df[\"TeamID_1\"] > matchups_df[\"TeamID_2\"], [\"TeamID_1\", \"TeamID_2\", \"TeamName_1\", \"TeamName_2\"]\n",
    "    ] = matchups_df.loc[\n",
    "        matchups_df[\"TeamID_1\"] > matchups_df[\"TeamID_2\"], [\"TeamID_2\", \"TeamID_1\", \"TeamName_2\", \"TeamName_1\"]\n",
    "    ].values\n",
    "    \n",
    "    matchups_df[\"Season\"] = 2021\n",
    "    matchups_df[\"ID\"] = matchups_df[\"Season\"].apply(str) + \"_\" + matchups_df[\"TeamID_1\"].apply(str) + \"_\" + matchups_df[\"TeamID_2\"].apply(str)\n",
    "    \n",
    "    matchups_df = merge_features(matchups_df, ppg_df, eff_df, rankings_df)\n",
    "    \n",
    "    return matchups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ID  Season  TeamID_1  TeamID_2  Result\n",
      "0     2021_1101_1190    2021      1101      1190       1\n",
      "1     2021_1291_1288    2021      1291      1288       1\n",
      "2     2021_1298_1203    2021      1298      1203       1\n",
      "3     2021_1462_1324    2021      1462      1324       1\n",
      "4     2021_1441_1423    2021      1441      1423       1\n",
      "...              ...     ...       ...       ...     ...\n",
      "7711  2021_1433_1382    2021      1433      1382       0\n",
      "7712  2021_1259_1159    2021      1259      1159       0\n",
      "7713  2021_1261_1104    2021      1261      1104       0\n",
      "7714  2021_1153_1222    2021      1153      1222       0\n",
      "7715  2021_1326_1228    2021      1326      1228       0\n",
      "\n",
      "[7716 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def prep_season_2021(season_results_df):\n",
    "    season_results_df = season_results_df.copy()\n",
    "    \n",
    "    seasons = season_results_df[\"Season\"]\n",
    "    all_teams_df = season_results_df[seasons == 2021].reset_index(drop=True)\n",
    "    \n",
    "    w_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    w_teams_df = w_teams_df.rename(columns={\"WTeamID\": \"TeamID_1\", \"LTeamID\": \"TeamID_2\"})\n",
    "    w_teams_df[\"Result\"] = 1\n",
    "    \n",
    "    l_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    l_teams_df = l_teams_df.rename(columns={\"WTeamID\": \"TeamID_2\", \"LTeamID\": \"TeamID_1\"})\n",
    "    l_teams_df[\"Result\"] = 0\n",
    "    \n",
    "    all_teams_df = pd.concat([w_teams_df, l_teams_df]).reset_index(drop=True)\n",
    "    \n",
    "    all_teams_df[\"ID\"] = all_teams_df[\"Season\"].apply(str) + \"_\" + all_teams_df[\"TeamID_1\"].apply(str) + \"_\" + all_teams_df[\"TeamID_2\"].apply(str)\n",
    "    \n",
    "    all_teams_df = all_teams_df[[\"ID\", \"Season\", \"TeamID_1\", \"TeamID_2\", \"Result\"]]\n",
    "    \n",
    "    return all_teams_df\n",
    "    \n",
    "print(prep_season_2021(m_regular_season_compact_results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_predictions_2021(sample_output_df, ncaa_tourney_results_df):\n",
    "    features_df = sample_output_df.copy()\n",
    "    features_df[\"Season\"] = features_df[\"ID\"].apply(lambda row: int(row[:4]))\n",
    "    features_df[\"TeamID_1\"] = features_df[\"ID\"].apply(lambda row: int(row[5:9]))\n",
    "    features_df[\"TeamID_2\"] = features_df[\"ID\"].apply(lambda row: int(row[10:14]))\n",
    "    features_df.drop([\"Pred\"], axis=1, inplace=True)\n",
    "    \n",
    "    ncaa_tourney_results_df = ncaa_tourney_results_df.copy()\n",
    "    seasons = ncaa_tourney_results_df[\"Season\"]\n",
    "    all_teams_df = ncaa_tourney_results_df[seasons == 2021].reset_index(drop=True)\n",
    "    \n",
    "    w_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    w_teams_df = w_teams_df.rename(columns={\"WTeamID\": \"TeamID_1\", \"LTeamID\": \"TeamID_2\"})\n",
    "    w_teams_df[\"Result\"] = 1\n",
    "    \n",
    "    l_teams_df = all_teams_df[[\"Season\", \"WTeamID\", \"LTeamID\"]]\n",
    "    l_teams_df = l_teams_df.rename(columns={\"WTeamID\": \"TeamID_2\", \"LTeamID\": \"TeamID_1\"})\n",
    "    l_teams_df[\"Result\"] = 0\n",
    "    \n",
    "    all_teams_df = pd.concat([w_teams_df, l_teams_df]).reset_index(drop=True)\n",
    "    \n",
    "    features_df = features_df.merge(all_teams_df, on=[\"Season\", \"TeamID_1\", \"TeamID_2\"], how=\"left\")\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_df = get_ppg(m_regular_season_compact_results_df)\n",
    "eff_df = get_efficiency(m_regular_season_detailed_results_df)\n",
    "rankings_df = get_rankings(m_massey_ordinals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID_1</th>\n",
       "      <th>TeamID_2</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_1101_1104</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021_1101_1111</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1111</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021_1101_1116</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1116</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021_1101_1124</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1124</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021_1101_1140</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1140</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>2021_1452_1457</td>\n",
       "      <td>2021</td>\n",
       "      <td>1452</td>\n",
       "      <td>1457</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>2021_1452_1458</td>\n",
       "      <td>2021</td>\n",
       "      <td>1452</td>\n",
       "      <td>1458</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>2021_1455_1457</td>\n",
       "      <td>2021</td>\n",
       "      <td>1455</td>\n",
       "      <td>1457</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>2021_1455_1458</td>\n",
       "      <td>2021</td>\n",
       "      <td>1455</td>\n",
       "      <td>1458</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>2021_1457_1458</td>\n",
       "      <td>2021</td>\n",
       "      <td>1457</td>\n",
       "      <td>1458</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2278 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  Season  TeamID_1  TeamID_2  Result\n",
       "0     2021_1101_1104    2021      1101      1104     NaN\n",
       "1     2021_1101_1111    2021      1101      1111     NaN\n",
       "2     2021_1101_1116    2021      1101      1116     NaN\n",
       "3     2021_1101_1124    2021      1101      1124     NaN\n",
       "4     2021_1101_1140    2021      1101      1140     NaN\n",
       "...              ...     ...       ...       ...     ...\n",
       "2273  2021_1452_1457    2021      1452      1457     NaN\n",
       "2274  2021_1452_1458    2021      1452      1458     NaN\n",
       "2275  2021_1455_1457    2021      1455      1457     NaN\n",
       "2276  2021_1455_1458    2021      1455      1458     NaN\n",
       "2277  2021_1457_1458    2021      1457      1458     NaN\n",
       "\n",
       "[2278 rows x 5 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_predictions_2021(sample_subm_df, m_ncaa_tourney_compact_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andy_kats_mock_mm_2021_df = prep2021(mock_matchups_df, ppg_df, eff_df, rankings_df)\n",
    "andy_kats_mock_mm_2021_df\n",
    "\n",
    "mm_2021_df = prep2021(matchups_df, ppg_df, eff_df, rankings_df)\n",
    "mm_2021_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = prep_predictions_2021(sample_subm_df, m_ncaa_tourney_compact_results_df)\n",
    "tourney_df = merge_features(features_df, ppg_df, eff_df, rankings_df)\n",
    "\n",
    "features_df = prep_season_2021(m_regular_season_compact_results_df)\n",
    "reg_season_df = merge_features(features_df, ppg_df, eff_df, rankings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID_1</th>\n",
       "      <th>TeamID_2</th>\n",
       "      <th>Result</th>\n",
       "      <th>PPGDiff</th>\n",
       "      <th>WPercDiff</th>\n",
       "      <th>OffEffDiff</th>\n",
       "      <th>DefEffDiff</th>\n",
       "      <th>MeanOrdinalRankDiff</th>\n",
       "      <th>MedianOrdinalRankDiff</th>\n",
       "      <th>MasseyOrdinalRankDiff</th>\n",
       "      <th>BPI RKDiff</th>\n",
       "      <th>SOS RKDiff</th>\n",
       "      <th>SOR RKDiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_1101_1190</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1190</td>\n",
       "      <td>1</td>\n",
       "      <td>8.053140</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>15.584541</td>\n",
       "      <td>5.922705</td>\n",
       "      <td>-48.480000</td>\n",
       "      <td>-49.5</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-64</td>\n",
       "      <td>153</td>\n",
       "      <td>-93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021_1291_1288</td>\n",
       "      <td>2021</td>\n",
       "      <td>1291</td>\n",
       "      <td>1288</td>\n",
       "      <td>1</td>\n",
       "      <td>-15.258107</td>\n",
       "      <td>-0.086124</td>\n",
       "      <td>-20.001595</td>\n",
       "      <td>-18.915205</td>\n",
       "      <td>-18.560000</td>\n",
       "      <td>-23.5</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-23</td>\n",
       "      <td>-72</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021_1298_1203</td>\n",
       "      <td>2021</td>\n",
       "      <td>1298</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "      <td>2.912854</td>\n",
       "      <td>0.539216</td>\n",
       "      <td>6.343137</td>\n",
       "      <td>-7.879811</td>\n",
       "      <td>-138.360000</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>-88</td>\n",
       "      <td>85</td>\n",
       "      <td>-188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021_1462_1324</td>\n",
       "      <td>2021</td>\n",
       "      <td>1462</td>\n",
       "      <td>1324</td>\n",
       "      <td>1</td>\n",
       "      <td>1.593862</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>3.283492</td>\n",
       "      <td>12.411323</td>\n",
       "      <td>-164.660000</td>\n",
       "      <td>-168.5</td>\n",
       "      <td>-156.0</td>\n",
       "      <td>-211</td>\n",
       "      <td>-66</td>\n",
       "      <td>-207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021_1441_1423</td>\n",
       "      <td>2021</td>\n",
       "      <td>1441</td>\n",
       "      <td>1423</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.057500</td>\n",
       "      <td>-0.015000</td>\n",
       "      <td>-1.211111</td>\n",
       "      <td>4.556111</td>\n",
       "      <td>-18.179184</td>\n",
       "      <td>-16.5</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>23</td>\n",
       "      <td>-117</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7711</th>\n",
       "      <td>2021_1433_1382</td>\n",
       "      <td>2021</td>\n",
       "      <td>1433</td>\n",
       "      <td>1382</td>\n",
       "      <td>0</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>-0.069231</td>\n",
       "      <td>-2.507692</td>\n",
       "      <td>3.086325</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7712</th>\n",
       "      <td>2021_1259_1159</td>\n",
       "      <td>2021</td>\n",
       "      <td>1259</td>\n",
       "      <td>1159</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.442939</td>\n",
       "      <td>-0.580392</td>\n",
       "      <td>-19.828164</td>\n",
       "      <td>-15.813983</td>\n",
       "      <td>145.460000</td>\n",
       "      <td>151.5</td>\n",
       "      <td>153.0</td>\n",
       "      <td>145</td>\n",
       "      <td>-92</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7713</th>\n",
       "      <td>2021_1261_1104</td>\n",
       "      <td>2021</td>\n",
       "      <td>1261</td>\n",
       "      <td>1104</td>\n",
       "      <td>0</td>\n",
       "      <td>2.157613</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.081070</td>\n",
       "      <td>-0.428807</td>\n",
       "      <td>19.734615</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7714</th>\n",
       "      <td>2021_1153_1222</td>\n",
       "      <td>2021</td>\n",
       "      <td>1153</td>\n",
       "      <td>1222</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.394649</td>\n",
       "      <td>-0.362876</td>\n",
       "      <td>-10.454849</td>\n",
       "      <td>-5.357860</td>\n",
       "      <td>102.429231</td>\n",
       "      <td>105.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>123</td>\n",
       "      <td>-40</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7715</th>\n",
       "      <td>2021_1326_1228</td>\n",
       "      <td>2021</td>\n",
       "      <td>1326</td>\n",
       "      <td>1228</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.498084</td>\n",
       "      <td>-0.093103</td>\n",
       "      <td>-7.721456</td>\n",
       "      <td>-8.177395</td>\n",
       "      <td>6.961538</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7716 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  Season  TeamID_1  TeamID_2  Result    PPGDiff  \\\n",
       "0     2021_1101_1190    2021      1101      1190       1   8.053140   \n",
       "1     2021_1291_1288    2021      1291      1288       1 -15.258107   \n",
       "2     2021_1298_1203    2021      1298      1203       1   2.912854   \n",
       "3     2021_1462_1324    2021      1462      1324       1   1.593862   \n",
       "4     2021_1441_1423    2021      1441      1423       1  -1.057500   \n",
       "...              ...     ...       ...       ...     ...        ...   \n",
       "7711  2021_1433_1382    2021      1433      1382       0   0.867521   \n",
       "7712  2021_1259_1159    2021      1259      1159       0 -16.442939   \n",
       "7713  2021_1261_1104    2021      1261      1104       0   2.157613   \n",
       "7714  2021_1153_1222    2021      1153      1222       0  -7.394649   \n",
       "7715  2021_1326_1228    2021      1326      1228       0  -3.498084   \n",
       "\n",
       "      WPercDiff  OffEffDiff  DefEffDiff  MeanOrdinalRankDiff  \\\n",
       "0      0.347826   15.584541    5.922705           -48.480000   \n",
       "1     -0.086124  -20.001595  -18.915205           -18.560000   \n",
       "2      0.539216    6.343137   -7.879811          -138.360000   \n",
       "3      0.219048    3.283492   12.411323          -164.660000   \n",
       "4     -0.015000   -1.211111    4.556111           -18.179184   \n",
       "...         ...         ...         ...                  ...   \n",
       "7711  -0.069231   -2.507692    3.086325            12.900000   \n",
       "7712  -0.580392  -19.828164  -15.813983           145.460000   \n",
       "7713  -0.133333    0.081070   -0.428807            19.734615   \n",
       "7714  -0.362876  -10.454849   -5.357860           102.429231   \n",
       "7715  -0.093103   -7.721456   -8.177395             6.961538   \n",
       "\n",
       "      MedianOrdinalRankDiff  MasseyOrdinalRankDiff  BPI RKDiff  SOS RKDiff  \\\n",
       "0                     -49.5                  -39.0         -64         153   \n",
       "1                     -23.5                  -27.0         -23         -72   \n",
       "2                    -138.0                 -101.0         -88          85   \n",
       "3                    -168.5                 -156.0        -211         -66   \n",
       "4                     -16.5                  -41.0          23        -117   \n",
       "...                     ...                    ...         ...         ...   \n",
       "7711                   12.0                   17.0          32          -9   \n",
       "7712                  151.5                  153.0         145         -92   \n",
       "7713                   19.5                   19.0          15           1   \n",
       "7714                  105.0                   91.0         123         -40   \n",
       "7715                    6.0                    5.0           7           4   \n",
       "\n",
       "      SOR RKDiff  \n",
       "0            -93  \n",
       "1             -5  \n",
       "2           -188  \n",
       "3           -207  \n",
       "4             -3  \n",
       "...          ...  \n",
       "7711           4  \n",
       "7712         202  \n",
       "7713          17  \n",
       "7714          80  \n",
       "7715           4  \n",
       "\n",
       "[7716 rows x 15 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_season_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_season_2021_df = reg_season_df[reg_season_df[\"Season\"] == 2021].copy()\n",
    "\n",
    "x_train = reg_season_2021_df[[\n",
    "    \"PPGDiff\", \"WPercDiff\", \"OffEffDiff\", \"DefEffDiff\",\n",
    "    \"MeanOrdinalRankDiff\",\"MedianOrdinalRankDiff\", \"MasseyOrdinalRankDiff\",\n",
    "    \"BPI RKDiff\", \"SOS RKDiff\", \"SOR RKDiff\"\n",
    "]]\n",
    "y_train = reg_season_2021_df[[\"Result\"]]\n",
    "x_test = tourney_df[[\n",
    "    \"PPGDiff\", \"WPercDiff\", \"OffEffDiff\", \"DefEffDiff\",\n",
    "    \"MeanOrdinalRankDiff\",\"MedianOrdinalRankDiff\", \"MasseyOrdinalRankDiff\",\n",
    "    \"BPI RKDiff\", \"SOS RKDiff\", \"SOR RKDiff\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>TeamID_1</th>\n",
       "      <th>TeamID_2</th>\n",
       "      <th>Result</th>\n",
       "      <th>PPGDiff</th>\n",
       "      <th>WPercDiff</th>\n",
       "      <th>OffEffDiff</th>\n",
       "      <th>DefEffDiff</th>\n",
       "      <th>MeanOrdinalRankDiff</th>\n",
       "      <th>MedianOrdinalRankDiff</th>\n",
       "      <th>MasseyOrdinalRankDiff</th>\n",
       "      <th>BPI RKDiff</th>\n",
       "      <th>SOS RKDiff</th>\n",
       "      <th>SOR RKDiff</th>\n",
       "      <th>TeamWProb_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_1101_1104</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.262319</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>-0.013043</td>\n",
       "      <td>-14.255072</td>\n",
       "      <td>76.614615</td>\n",
       "      <td>76.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>74</td>\n",
       "      <td>262</td>\n",
       "      <td>70</td>\n",
       "      <td>0.142567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021_1101_1111</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.189533</td>\n",
       "      <td>0.284420</td>\n",
       "      <td>17.036957</td>\n",
       "      <td>4.563446</td>\n",
       "      <td>-96.880000</td>\n",
       "      <td>-96.5</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-92</td>\n",
       "      <td>51</td>\n",
       "      <td>-114</td>\n",
       "      <td>0.831619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021_1101_1116</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.747239</td>\n",
       "      <td>0.040373</td>\n",
       "      <td>-3.369393</td>\n",
       "      <td>-11.196342</td>\n",
       "      <td>70.210769</td>\n",
       "      <td>70.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>69</td>\n",
       "      <td>234</td>\n",
       "      <td>65</td>\n",
       "      <td>0.159385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021_1101_1124</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.635467</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>-8.093599</td>\n",
       "      <td>2.098631</td>\n",
       "      <td>80.441538</td>\n",
       "      <td>81.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>81</td>\n",
       "      <td>227</td>\n",
       "      <td>72</td>\n",
       "      <td>0.116458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021_1101_1140</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.495652</td>\n",
       "      <td>0.066087</td>\n",
       "      <td>3.014957</td>\n",
       "      <td>-2.065739</td>\n",
       "      <td>62.813333</td>\n",
       "      <td>60.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>54</td>\n",
       "      <td>214</td>\n",
       "      <td>56</td>\n",
       "      <td>0.194185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>2021_1452_1457</td>\n",
       "      <td>2021</td>\n",
       "      <td>1452</td>\n",
       "      <td>1457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.278292</td>\n",
       "      <td>-0.291667</td>\n",
       "      <td>-4.224588</td>\n",
       "      <td>-1.801852</td>\n",
       "      <td>-46.321538</td>\n",
       "      <td>-51.5</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-59</td>\n",
       "      <td>-317</td>\n",
       "      <td>-30</td>\n",
       "      <td>0.695932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>2021_1452_1458</td>\n",
       "      <td>2021</td>\n",
       "      <td>1452</td>\n",
       "      <td>1458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.194409</td>\n",
       "      <td>0.080460</td>\n",
       "      <td>12.629147</td>\n",
       "      <td>7.633206</td>\n",
       "      <td>-8.221538</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.545738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>2021_1455_1457</td>\n",
       "      <td>2021</td>\n",
       "      <td>1455</td>\n",
       "      <td>1457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.670322</td>\n",
       "      <td>-0.221491</td>\n",
       "      <td>-13.376462</td>\n",
       "      <td>-0.358187</td>\n",
       "      <td>-9.060000</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-240</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.628749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>2021_1455_1458</td>\n",
       "      <td>2021</td>\n",
       "      <td>1455</td>\n",
       "      <td>1458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.802380</td>\n",
       "      <td>0.150635</td>\n",
       "      <td>3.477274</td>\n",
       "      <td>9.076870</td>\n",
       "      <td>29.040000</td>\n",
       "      <td>34.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>76</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>0.470613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>2021_1457_1458</td>\n",
       "      <td>2021</td>\n",
       "      <td>1457</td>\n",
       "      <td>1458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.472701</td>\n",
       "      <td>0.372126</td>\n",
       "      <td>16.853736</td>\n",
       "      <td>9.435057</td>\n",
       "      <td>38.100000</td>\n",
       "      <td>42.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64</td>\n",
       "      <td>329</td>\n",
       "      <td>17</td>\n",
       "      <td>0.344222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2278 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  Season  TeamID_1  TeamID_2  Result    PPGDiff  \\\n",
       "0     2021_1101_1104    2021      1101      1104     NaN  -3.262319   \n",
       "1     2021_1101_1111    2021      1101      1111     NaN   9.189533   \n",
       "2     2021_1101_1116    2021      1101      1116     NaN  -5.747239   \n",
       "3     2021_1101_1124    2021      1101      1124     NaN  -7.635467   \n",
       "4     2021_1101_1140    2021      1101      1140     NaN  -0.495652   \n",
       "...              ...     ...       ...       ...     ...        ...   \n",
       "2273  2021_1452_1457    2021      1452      1457     NaN  -3.278292   \n",
       "2274  2021_1452_1458    2021      1452      1458     NaN   7.194409   \n",
       "2275  2021_1455_1457    2021      1455      1457     NaN  -8.670322   \n",
       "2276  2021_1455_1458    2021      1455      1458     NaN   1.802380   \n",
       "2277  2021_1457_1458    2021      1457      1458     NaN  10.472701   \n",
       "\n",
       "      WPercDiff  OffEffDiff  DefEffDiff  MeanOrdinalRankDiff  \\\n",
       "0      0.026087   -0.013043  -14.255072            76.614615   \n",
       "1      0.284420   17.036957    4.563446           -96.880000   \n",
       "2      0.040373   -3.369393  -11.196342            70.210769   \n",
       "3     -0.090580   -8.093599    2.098631            80.441538   \n",
       "4      0.066087    3.014957   -2.065739            62.813333   \n",
       "...         ...         ...         ...                  ...   \n",
       "2273  -0.291667   -4.224588   -1.801852           -46.321538   \n",
       "2274   0.080460   12.629147    7.633206            -8.221538   \n",
       "2275  -0.221491  -13.376462   -0.358187            -9.060000   \n",
       "2276   0.150635    3.477274    9.076870            29.040000   \n",
       "2277   0.372126   16.853736    9.435057            38.100000   \n",
       "\n",
       "      MedianOrdinalRankDiff  MasseyOrdinalRankDiff  BPI RKDiff  SOS RKDiff  \\\n",
       "0                      76.0                   98.0          74         262   \n",
       "1                     -96.5                  -76.0         -92          51   \n",
       "2                      70.0                   95.0          69         234   \n",
       "3                      81.0                  103.0          81         227   \n",
       "4                      60.0                   81.0          54         214   \n",
       "...                     ...                    ...         ...         ...   \n",
       "2273                  -51.5                  -61.0         -59        -317   \n",
       "2274                   -9.0                   13.0           5          12   \n",
       "2275                   -8.0                  -29.0          12        -240   \n",
       "2276                   34.5                   45.0          76          89   \n",
       "2277                   42.5                   74.0          64         329   \n",
       "\n",
       "      SOR RKDiff  TeamWProb_1  \n",
       "0             70     0.142567  \n",
       "1           -114     0.831619  \n",
       "2             65     0.159385  \n",
       "3             72     0.116458  \n",
       "4             56     0.194185  \n",
       "...          ...          ...  \n",
       "2273         -30     0.695932  \n",
       "2274         -13     0.545738  \n",
       "2275          -4     0.628749  \n",
       "2276          13     0.470613  \n",
       "2277          17     0.344222  \n",
       "\n",
       "[2278 rows x 16 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tourney_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, n_jobs=-1, verbose=1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(penalty=\"l2\", random_state=None, max_iter=1000, verbose=1, n_jobs=-1)\n",
    "\n",
    "log_reg.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TeamID_1</th>\n",
       "      <th>TeamID_2</th>\n",
       "      <th>TeamName_1</th>\n",
       "      <th>TeamName_2</th>\n",
       "      <th>TeamWProb_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_1101_1104</td>\n",
       "      <td>1101</td>\n",
       "      <td>1104</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.142567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021_1101_1111</td>\n",
       "      <td>1101</td>\n",
       "      <td>1111</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Appalachian St</td>\n",
       "      <td>0.831619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021_1101_1116</td>\n",
       "      <td>1101</td>\n",
       "      <td>1116</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.159385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021_1101_1124</td>\n",
       "      <td>1101</td>\n",
       "      <td>1124</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>0.116458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021_1101_1140</td>\n",
       "      <td>1101</td>\n",
       "      <td>1140</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>BYU</td>\n",
       "      <td>0.194185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>2021_1452_1457</td>\n",
       "      <td>1452</td>\n",
       "      <td>1457</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Winthrop</td>\n",
       "      <td>0.695932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>2021_1452_1458</td>\n",
       "      <td>1452</td>\n",
       "      <td>1458</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>0.545738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>2021_1455_1457</td>\n",
       "      <td>1455</td>\n",
       "      <td>1457</td>\n",
       "      <td>Wichita St</td>\n",
       "      <td>Winthrop</td>\n",
       "      <td>0.628749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276</th>\n",
       "      <td>2021_1455_1458</td>\n",
       "      <td>1455</td>\n",
       "      <td>1458</td>\n",
       "      <td>Wichita St</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>0.470613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277</th>\n",
       "      <td>2021_1457_1458</td>\n",
       "      <td>1457</td>\n",
       "      <td>1458</td>\n",
       "      <td>Winthrop</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>0.344222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2278 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  TeamID_1  TeamID_2     TeamName_1      TeamName_2  \\\n",
       "0     2021_1101_1104      1101      1104    Abilene Chr         Alabama   \n",
       "1     2021_1101_1111      1101      1111    Abilene Chr  Appalachian St   \n",
       "2     2021_1101_1116      1101      1116    Abilene Chr        Arkansas   \n",
       "3     2021_1101_1124      1101      1124    Abilene Chr          Baylor   \n",
       "4     2021_1101_1140      1101      1140    Abilene Chr             BYU   \n",
       "...              ...       ...       ...            ...             ...   \n",
       "2273  2021_1452_1457      1452      1457  West Virginia        Winthrop   \n",
       "2274  2021_1452_1458      1452      1458  West Virginia       Wisconsin   \n",
       "2275  2021_1455_1457      1455      1457     Wichita St        Winthrop   \n",
       "2276  2021_1455_1458      1455      1458     Wichita St       Wisconsin   \n",
       "2277  2021_1457_1458      1457      1458       Winthrop       Wisconsin   \n",
       "\n",
       "      TeamWProb_1  \n",
       "0        0.142567  \n",
       "1        0.831619  \n",
       "2        0.159385  \n",
       "3        0.116458  \n",
       "4        0.194185  \n",
       "...           ...  \n",
       "2273     0.695932  \n",
       "2274     0.545738  \n",
       "2275     0.628749  \n",
       "2276     0.470613  \n",
       "2277     0.344222  \n",
       "\n",
       "[2278 rows x 6 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = log_reg.predict_proba(x_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "tourney_df[\"TeamWProb_1\"] = y_pred\n",
    "\n",
    "# tourney_df[[\"TeamName_1\", \"TeamName_2\", \"TeamWProb_1\"]]\n",
    "\n",
    "tourney_df_disp_teams = pd.merge(tourney_df[[\"ID\", \"TeamID_1\", \"TeamID_2\", \"TeamWProb_1\"]], m_teams_df[[\"TeamName\", \"TeamID\"]], left_on=\"TeamID_1\", right_on=\"TeamID\", how=\"left\")\n",
    "tourney_df_disp_teams.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "tourney_df_disp_teams = pd.merge(tourney_df_disp_teams, m_teams_df[[\"TeamName\", \"TeamID\"]], left_on=\"TeamID_2\", right_on=\"TeamID\", how=\"left\")\n",
    "tourney_df_disp_teams.drop([\"TeamID\"], axis=1, inplace=True)\n",
    "tourney_df_disp_teams = tourney_df_disp_teams.rename(columns={\"TeamName_x\": \"TeamName_1\", \"TeamName_y\": \"TeamName_2\"})\n",
    "# tourney_df_disp_teams.drop([\"TeamID_1\", \"TeamID_2\"], axis=1, inplace=True)\n",
    "tourney_df_disp_teams = tourney_df_disp_teams[[\"ID\", \"TeamID_1\", \"TeamID_2\", \"TeamName_1\", \"TeamName_2\", \"TeamWProb_1\"]]\n",
    "tourney_df_disp_teams\n",
    "\n",
    "# tourney_df_disp_teams.to_csv(\"bracket.csv\", index=False)\n",
    "\n",
    "# y_pred = log_reg.predict_proba(\n",
    "#     tourney_df[[\n",
    "#         \"PPGDiff\", \"WPercDiff\", \"OffEffDiff\", \"DefEffDiff\",\n",
    "#         \"MeanOrdinalRankDiff\",\"MedianOrdinalRankDiff\", \"MasseyOrdinalRankDiff\",\n",
    "#         \"BPI RKDiff\", \"SOS RKDiff\", \"SOR RKDiff\"\n",
    "#     ]]\n",
    "# )\n",
    "# y_pred = y_pred[:, 1]\n",
    "\n",
    "# stage_2_submission_df = tourney_df[[\"ID\"]].copy()\n",
    "# stage_2_submission_df[\"Pred\"] = y_pred\n",
    "\n",
    "# stage_2_submission_df[\"TeamID_1\"] = stage_1_submission_df[\"ID\"].apply(lambda row: row[5:9])\n",
    "# stage_2_submission_df[\"TeamID_2\"] = stage_1_submission_df[\"ID\"].apply(lambda row: row[10:14])\n",
    "# stage_2_submission_df.merge(m_teams_df)\n",
    "# stage_2_submission_df\n",
    "# stage_2_submission_df.to_csv(m_subm_stage_2_output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_rd_tms = [\n",
    "    \"Gonzaga\", \"Appalachian State\",\n",
    "    \"Oklahoma\", \"Missouri\",\n",
    "    \"Creighton\", \"UC Santa Barbara\",\n",
    "    \"Virginia\", \"Ohio\",\n",
    "    \"USC\", \"Drake\",\n",
    "    \"Kansas\", \"Eastern Washington\",\n",
    "    \"Oregon\", \"VCU\",\n",
    "    \"Iowa\", \"Grand Canyon\",\n",
    "    \"Michigan\", \"Texas Southern\",\n",
    "    \"LSU\", \"St. Bonaventure\",\n",
    "    \"Colorado\", \"Georgetown\",\n",
    "    \"Florida State\", \"UNC Greensboro\",\n",
    "    \"BYU\", \"Michigan State\",\n",
    "    \"Texas\", \"Abilene Christian\",\n",
    "    \"UConn\", \"Maryland\",\n",
    "    \"Alabama\", \"Iona\",\n",
    "    \"Baylor\", \"Hartford\",\n",
    "    \"North Carolina\", \"Wisconsin\",\n",
    "    \"Villanova\", \"Winthrop\",\n",
    "    \"Purdue\", \"North Texas\",\n",
    "    \"Texas Tech\", \"Utah State\",\n",
    "    \"Arkansas\", \"Colgate\",\n",
    "    \"Florida\", \"Virginia Tech\",\n",
    "    \"Ohio State\", \"Oral Roberts\",\n",
    "    \"Illinois\", \"Drexel\",\n",
    "    \"Loyola-Chicago\", \"Georgia Tech\",\n",
    "    \"Tennessee\", \"Oregon State\",\n",
    "    \"Oklahoma State\", \"Liberty\",\n",
    "    \"San Diego State\", \"Syracuse\",\n",
    "    \"West Virginia\", \"Morehead State\",\n",
    "    \"Clemson\", \"Rutgers\",\n",
    "    \"Houston\", \"Cleveland State\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Winners from Each Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Round Winners:\n",
      "- gonzaga\n",
      "- missouri\n",
      "- creighton\n",
      "- virginia\n",
      "- usc\n",
      "- kansas\n",
      "- oregon\n",
      "- iowa\n",
      "- michigan\n",
      "- lsu\n",
      "- colorado\n",
      "- florida state\n",
      "- byu\n",
      "- texas\n",
      "- uconn\n",
      "- alabama\n",
      "- baylor\n",
      "- north carolina\n",
      "- villanova\n",
      "- purdue\n",
      "- texas tech\n",
      "- arkansas\n",
      "- florida\n",
      "- ohio state\n",
      "- illinois\n",
      "- georgia tech\n",
      "- tennessee\n",
      "- oklahoma state\n",
      "- san diego state\n",
      "- west virginia\n",
      "- clemson\n",
      "- houston\n",
      "\n",
      "Second Round Winners:\n",
      "- gonzaga\n",
      "- creighton\n",
      "- kansas\n",
      "- iowa\n",
      "- michigan\n",
      "- florida state\n",
      "- texas\n",
      "- alabama\n",
      "- baylor\n",
      "- purdue\n",
      "- arkansas\n",
      "- ohio state\n",
      "- illinois\n",
      "- oklahoma state\n",
      "- san diego state\n",
      "- houston\n",
      "\n",
      "Sweet 16 Winners:\n",
      "- gonzaga\n",
      "- iowa\n",
      "- michigan\n",
      "- alabama\n",
      "- baylor\n",
      "- arkansas\n",
      "- illinois\n",
      "- houston\n",
      "\n",
      "Elite 8 Winners:\n",
      "- gonzaga\n",
      "- michigan\n",
      "- baylor\n",
      "- illinois\n",
      "\n",
      "Final 4 Winners:\n",
      "- gonzaga\n",
      "- baylor\n",
      "\n",
      "NCAA Championship Winner:\n",
      "- gonzaga\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_mm_bracket(first_rd_tms, preds_df):\n",
    "    preds_df = preds_df.copy()\n",
    "    \n",
    "    first_rd_tms = [team.lower() for team in first_rd_tms]\n",
    "    first_rd_tms_df = pd.DataFrame({\"TeamName\": first_rd_tms})\n",
    "    first_rd_tms_df = pd.merge(first_rd_tms_df, m_team_spellings_df, left_on=\"TeamName\", right_on=\"TeamNameSpelling\", how=\"left\").reset_index(drop=True)\n",
    "    first_rd_tms_df.drop([\"TeamNameSpelling\"], axis=1, inplace=True)\n",
    "    \n",
    "    df = pd.DataFrame(first_rd_tms_df.values.reshape(-1, 4), columns=[\"TeamName_1\", \"TeamID_1\", \"TeamName_2\", \"TeamID_2\"])\n",
    "    \n",
    "    df.loc[\n",
    "        df[\"TeamID_1\"] > df[\"TeamID_2\"], [\"TeamID_1\", \"TeamID_2\", \"TeamName_1\", \"TeamName_2\"]\n",
    "    ] = df.loc[\n",
    "        df[\"TeamID_1\"] > df[\"TeamID_2\"], [\"TeamID_2\", \"TeamID_1\", \"TeamName_2\", \"TeamName_1\"]\n",
    "    ].values\n",
    "    \n",
    "    df[\"Season\"] = 2021\n",
    "    df[\"ID\"] = df[\"Season\"].apply(str) + \"_\" + df[\"TeamID_1\"].apply(str) + \"_\" + df[\"TeamID_2\"].apply(str)\n",
    "    \n",
    "    df = pd.merge(df, preds_df[[\"ID\", \"TeamWProb_1\"]], on=\"ID\", how=\"inner\")\n",
    "    \n",
    "    first_rd_w_tms = [row[\"TeamName_1\"] if row[\"TeamWProb_1\"] >= 0.5 else row[\"TeamName_2\"] for index, row in df.iterrows()]\n",
    "    \n",
    "    second_rd_tms_df = pd.DataFrame({\"TeamName\": first_rd_w_tms})\n",
    "    second_rd_tms_df = pd.merge(second_rd_tms_df, m_team_spellings_df, left_on=\"TeamName\", right_on=\"TeamNameSpelling\", how=\"left\").reset_index(drop=True)\n",
    "    second_rd_tms_df.drop([\"TeamNameSpelling\"], axis=1, inplace=True)\n",
    "    \n",
    "    df = pd.DataFrame(second_rd_tms_df.values.reshape(-1, 4), columns=[\"TeamName_1\", \"TeamID_1\", \"TeamName_2\", \"TeamID_2\"])\n",
    "    \n",
    "    df.loc[\n",
    "        df[\"TeamID_1\"] > df[\"TeamID_2\"], [\"TeamID_1\", \"TeamID_2\", \"TeamName_1\", \"TeamName_2\"]\n",
    "    ] = df.loc[\n",
    "        df[\"TeamID_1\"] > df[\"TeamID_2\"], [\"TeamID_2\", \"TeamID_1\", \"TeamName_2\", \"TeamName_1\"]\n",
    "    ].values\n",
    "    \n",
    "    df[\"Season\"] = 2021\n",
    "    df[\"ID\"] = df[\"Season\"].apply(str) + \"_\" + df[\"TeamID_1\"].apply(str) + \"_\" + df[\"TeamID_2\"].apply(str)\n",
    "    \n",
    "    df = pd.merge(df, preds_df[[\"ID\", \"TeamWProb_1\"]], on=\"ID\", how=\"inner\")\n",
    "    \n",
    "    second_rd_w_tms = [row[\"TeamName_1\"] if row[\"TeamWProb_1\"] >= 0.5 else row[\"TeamName_2\"] for index, row in df.iterrows()]\n",
    "    \n",
    "    sweet_16_tms_df = pd.DataFrame({\"TeamName\": second_rd_w_tms})\n",
    "    sweet_16_tms_df = pd.merge(sweet_16_tms_df, m_team_spellings_df, left_on=\"TeamName\", right_on=\"TeamNameSpelling\", how=\"left\").reset_index(drop=True)\n",
    "    sweet_16_tms_df.drop([\"TeamNameSpelling\"], axis=1, inplace=True)\n",
    "    \n",
    "    df = pd.DataFrame(sweet_16_tms_df.values.reshape(-1, 4), columns=[\"TeamName_1\", \"TeamID_1\", \"TeamName_2\", \"TeamID_2\"])\n",
    "    \n",
    "    df.loc[\n",
    "        df[\"TeamID_1\"] > df[\"TeamID_2\"], [\"TeamID_1\", \"TeamID_2\", \"TeamName_1\", \"TeamName_2\"]\n",
    "    ] = df.loc[\n",
    "        df[\"TeamID_1\"] > df[\"TeamID_2\"], [\"TeamID_2\", \"TeamID_1\", \"TeamName_2\", \"TeamName_1\"]\n",
    "    ].values\n",
    "    \n",
    "    df[\"Season\"] = 2021\n",
    "    df[\"ID\"] = df[\"Season\"].apply(str) + \"_\" + df[\"TeamID_1\"].apply(str) + \"_\" + df[\"TeamID_2\"].apply(str)\n",
    "    \n",
    "    df = pd.merge(df, preds_df[[\"ID\", \"TeamWProb_1\"]], on=\"ID\", how=\"inner\")\n",
    "    \n",
    "    sweet_16_w_tms = [row[\"TeamName_1\"] if row[\"TeamWProb_1\"] >= 0.5 else row[\"TeamName_2\"] for index, row in df.iterrows()]\n",
    "    \n",
    "    elite_8_tms_df = pd.DataFrame({\"TeamName\": sweet_16_w_tms})\n",
    "    elite_8_tms_df = pd.merge(elite_8_tms_df, m_team_spellings_df, left_on=\"TeamName\", right_on=\"TeamNameSpelling\", how=\"left\").reset_index(drop=True)\n",
    "    elite_8_tms_df.drop([\"TeamNameSpelling\"], axis=1, inplace=True)\n",
    "    \n",
    "    df = pd.DataFrame(elite_8_tms_df.values.reshape(-1, 4), columns=[\"TeamName_1\", \"TeamID_1\", \"TeamName_2\", \"TeamID_2\"])\n",
    "    \n",
    "    df.loc[\n",
    "        df[\"TeamID_1\"] > df[\"TeamID_2\"], [\"TeamID_1\", \"TeamID_2\", \"TeamName_1\", \"TeamName_2\"]\n",
    "    ] = df.loc[\n",
    "        df[\"TeamID_1\"] > df[\"TeamID_2\"], [\"TeamID_2\", \"TeamID_1\", \"TeamName_2\", \"TeamName_1\"]\n",
    "    ].values\n",
    "    \n",
    "    df[\"Season\"] = 2021\n",
    "    df[\"ID\"] = df[\"Season\"].apply(str) + \"_\" + df[\"TeamID_1\"].apply(str) + \"_\" + df[\"TeamID_2\"].apply(str)\n",
    "    \n",
    "    df = pd.merge(df, preds_df[[\"ID\", \"TeamWProb_1\"]], on=\"ID\", how=\"inner\")\n",
    "    \n",
    "    elite_8_w_tms = [row[\"TeamName_1\"] if row[\"TeamWProb_1\"] >= 0.5 else row[\"TeamName_2\"] for index, row in df.iterrows()]\n",
    "    \n",
    "    final_4_tms_df = pd.DataFrame({\"TeamName\": elite_8_w_tms})\n",
    "    final_4_tms_df = pd.merge(final_4_tms_df, m_team_spellings_df, left_on=\"TeamName\", right_on=\"TeamNameSpelling\", how=\"left\").reset_index(drop=True)\n",
    "    final_4_tms_df.drop([\"TeamNameSpelling\"], axis=1, inplace=True)\n",
    "    \n",
    "    df = pd.DataFrame(final_4_tms_df.values.reshape(-1, 4), columns=[\"TeamName_1\", \"TeamID_1\", \"TeamName_2\", \"TeamID_2\"])\n",
    "    \n",
    "    df.loc[\n",
    "        df[\"TeamID_1\"] > df[\"TeamID_2\"], [\"TeamID_1\", \"TeamID_2\", \"TeamName_1\", \"TeamName_2\"]\n",
    "    ] = df.loc[\n",
    "        df[\"TeamID_1\"] > df[\"TeamID_2\"], [\"TeamID_2\", \"TeamID_1\", \"TeamName_2\", \"TeamName_1\"]\n",
    "    ].values\n",
    "    \n",
    "    df[\"Season\"] = 2021\n",
    "    df[\"ID\"] = df[\"Season\"].apply(str) + \"_\" + df[\"TeamID_1\"].apply(str) + \"_\" + df[\"TeamID_2\"].apply(str)\n",
    "    \n",
    "    df = pd.merge(df, preds_df[[\"ID\", \"TeamWProb_1\"]], on=\"ID\", how=\"inner\")\n",
    "    \n",
    "    final_4_w_tms = [row[\"TeamName_1\"] if row[\"TeamWProb_1\"] >= 0.5 else row[\"TeamName_2\"] for index, row in df.iterrows()]\n",
    "    \n",
    "    champ_tms_df = pd.DataFrame({\"TeamName\": final_4_w_tms})\n",
    "    champ_tms_df = pd.merge(champ_tms_df, m_team_spellings_df, left_on=\"TeamName\", right_on=\"TeamNameSpelling\", how=\"left\").reset_index(drop=True)\n",
    "    champ_tms_df.drop([\"TeamNameSpelling\"], axis=1, inplace=True)\n",
    "    \n",
    "    df = pd.DataFrame(champ_tms_df.values.reshape(-1, 4), columns=[\"TeamName_1\", \"TeamID_1\", \"TeamName_2\", \"TeamID_2\"])\n",
    "    \n",
    "    df.loc[\n",
    "        df[\"TeamID_1\"] > df[\"TeamID_2\"], [\"TeamID_1\", \"TeamID_2\", \"TeamName_1\", \"TeamName_2\"]\n",
    "    ] = df.loc[\n",
    "        df[\"TeamID_1\"] > df[\"TeamID_2\"], [\"TeamID_2\", \"TeamID_1\", \"TeamName_2\", \"TeamName_1\"]\n",
    "    ].values\n",
    "    \n",
    "    df[\"Season\"] = 2021\n",
    "    df[\"ID\"] = df[\"Season\"].apply(str) + \"_\" + df[\"TeamID_1\"].apply(str) + \"_\" + df[\"TeamID_2\"].apply(str)\n",
    "    \n",
    "    df = pd.merge(df, preds_df[[\"ID\", \"TeamWProb_1\"]], on=\"ID\", how=\"inner\")\n",
    "    \n",
    "    champ_w_tm = [row[\"TeamName_1\"] if row[\"TeamWProb_1\"] >= 0.5 else row[\"TeamName_2\"] for index, row in df.iterrows()]\n",
    "    \n",
    "    nl = \"\\n\"\n",
    "    print(f\"First Round Winners:{nl + '- '}{(nl + '- ').join((*first_rd_w_tms, ))}{nl}\")\n",
    "    print(f\"Second Round Winners:{nl + '- '}{(nl + '- ').join((*second_rd_w_tms, ))}{nl}\")\n",
    "    print(f\"Sweet 16 Winners:{nl + '- '}{(nl + '- ').join((*sweet_16_w_tms, ))}{nl}\")\n",
    "    print(f\"Elite 8 Winners:{nl + '- '}{(nl + '- ').join((*elite_8_w_tms, ))}{nl}\")\n",
    "    print(f\"Final 4 Winners:{nl + '- '}{(nl + '- ').join((*final_4_w_tms, ))}{nl}\")\n",
    "    print(f\"NCAA Championship Winner:{(nl + '- ')}{nl.join((*champ_w_tm, ))}{nl}\")\n",
    "    \n",
    "generate_mm_bracket(first_rd_tms, tourney_df_disp_teams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
